__BRYTHON__.use_VFS = true;
var scripts = {"$timestamp": 1636219033364, "bpmn2camel.brython-cli-script": [".py", "#!c:\\users\\rramasubramanian\\appdata\\local\\programs\\python\\python39-32\\python.exe\n\nimport re\nimport sys\n\n\n__requires__='brython==3.10.3'\n\ntry :\n from importlib.metadata import distribution\nexcept ImportError:\n try :\n  from importlib_metadata import distribution\n except ImportError:\n  from pkg_resources import load_entry_point\n  \n  \ndef importlib_load_entry_point(spec,group,name):\n dist_name,_,_=spec.partition('==')\n matches=(\n entry_point\n for entry_point in distribution(dist_name).entry_points\n if entry_point.group ==group and entry_point.name ==name\n )\n return next(matches).load()\n \n \nglobals().setdefault('load_entry_point',importlib_load_entry_point)\n\n\nif __name__ =='__main__':\n sys.argv[0]=re.sub(r'(-script\\.pyw?|\\.exe)?$','',sys.argv[0])\n sys.exit(load_entry_point('brython==3.10.3','console_scripts','brython-cli')())\n", ["importlib.metadata", "importlib_metadata", "pkg_resources", "re", "sys"]], "bpmn2camel": [".py", "", [], 1], "bpmn2camel.bpmn_process.bpmn2json": [".py", "import untangle\nfrom bpmn_process import bpmn_messageflow\nfrom bpmn_process import bpmn_endevent\nfrom bpmn_process import bpmn_messagestartevent\nfrom bpmn_process import bpmn_servicetask\nfrom bpmn_process import bpmn_parallelgateway\nfrom bpmn_process import bpmn_inclusivegateway\nfrom bpmn_process import bpmn_intermediate_messagethrowevent\nimport json\n\n\nclass BpmnXml2py:\n bpmnxml2py=None ;\n bpmn_dict={}\n \n def load_bpmnxml2py(self,filepath):\n  self.bpmnxml2py=untangle.parse(filepath)\n  \n def get_configuration_properties(self,elements):\n  configuration_properties={}\n  for each_element in elements:\n   configuration_properties[str(each_element['name'])]=str(each_element['value'])\n  return configuration_properties\n  \n def get_incomings(self,element):\n  incoming_flows=[]\n  incomings=element.bpmn_incoming\n  for each_incoming in incomings:\n   incoming_flows.append(str(each_incoming.cdata))\n  return list(set(incoming_flows))\n  \n def get_outgoings(self,element):\n  outgoing_flows=[]\n  outgoings=element.bpmn_outgoing\n  for each_outgoing in outgoings:\n   outgoing_flows.append(str(each_outgoing.cdata))\n  return list(set(outgoing_flows))\n  \n def get_processes(self,bpmnxml2py):\n  elements_in_mf=bpmnxml2py.bpmn_definitions.bpmn_process.children\n  for each_element_of_mf in elements_in_mf:\n   if each_element_of_mf.__dict__['_name']==\"bpmn_endEvent\":\n    self.extract_end_event_metadata(each_element_of_mf)\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_startEvent\":\n    self._extract_msg_start_event_metadata(each_element_of_mf)\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_inclusiveGateway\":\n    self._extract_inclusive_gateway_metadata(each_element_of_mf)\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_intermediateThrowEvent\":\n    self._extract_msg_throw_event_metadata(each_element_of_mf)\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_intermediateCatchEvent\":\n    pass\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_parallelGateway\":\n    self._extract_parallel_gateway_metadata(each_element_of_mf)\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_serviceTask\":\n    self._extract_service_task_metadata(each_element_of_mf)\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_sequenceFlow\":\n    pass\n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_extensionElements\":\n    self._extract_extenstion_configuration_metadata(bpmnxml2py)\n    \n    \n   if each_element_of_mf.__dict__['_name']==\"bpmn_subProcess\":\n    pass\n    \n   print(each_element_of_mf['name'])\n   \n def _extract_extenstion_configuration_metadata(self,bpmnxml2py):\n  self.mf_name=bpmnxml2py.bpmn_definitions.bpmn_process['name']\n  self.mf_id=bpmnxml2py.bpmn_definitions.bpmn_process['id']\n  self.mf_configuration_properties=self.get_configuration_properties(\n  bpmnxml2py.bpmn_definitions.bpmn_process.bpmn_extensionElements.camunda_properties.camunda_property)\n  mf=bpmn_messageflow.MessageFlow(self.mf_name,self.mf_id,\"MessageFlow\",\n  self.mf_configuration_properties)\n  s=json.dumps(mf.__dict__)\n  self.bpmn_dict[str(bpmnxml2py.bpmn_definitions.bpmn_process['name'])]=json.loads(s)\n  \n def _extract_service_task_metadata(self,each_element_of_mf):\n  self.service_task_name=each_element_of_mf['name']\n  self.service_task_id=each_element_of_mf['id']\n  self.service_task_configuration__properties=self.get_configuration_properties(\n  each_element_of_mf.bpmn_extensionElements.camunda_properties.camunda_property)\n  self.serivce_task_incoming=self.get_incomings(each_element_of_mf)\n  self.serivce_task_outgoing=self.get_outgoings(each_element_of_mf)\n  service_task=bpmn_servicetask.ServiceTask(self.service_task_name,self.service_task_id,\"ServiceTask\",\n  self.serivce_task_incoming,self.serivce_task_outgoing,\n  self.service_task_configuration__properties)\n  s=json.dumps(service_task.__dict__)\n  self.bpmn_dict[str(each_element_of_mf['id'])]=json.loads(s)\n  \n def _extract_parallel_gateway_metadata(self,each_element_of_mf):\n  self.parallel_gateway_name=each_element_of_mf['name']\n  self.parallel_gateway_id=each_element_of_mf['id']\n  self.parallel_gateway_configuration=self.get_configuration_properties(\n  each_element_of_mf.bpmn_extensionElements.camunda_properties.camunda_property)\n  self.parallel_gateway_incoming=self.get_incomings(each_element_of_mf)\n  self.parallel_gateway_outgoing=self.get_outgoings(each_element_of_mf)\n  parallel_gateway=bpmn_parallelgateway.ParallelGateway(self.parallel_gateway_name,\n  self.parallel_gateway_id,\"ParallelGateway\",\n  self.parallel_gateway_incoming,\n  self.parallel_gateway_outgoing,\n  self.parallel_gateway_configuration)\n  s=json.dumps(parallel_gateway.__dict__)\n  self.bpmn_dict[str(each_element_of_mf['id'])]=json.loads(s)\n  \n def _extract_msg_throw_event_metadata(self,each_element_of_mf):\n  self.message_throwevent_name=each_element_of_mf['name']\n  self.message_throwevent_id=each_element_of_mf['id']\n  self.message_throwevent_configuration=self.get_configuration_properties(\n  each_element_of_mf.bpmn_extensionElements.camunda_properties.camunda_property)\n  self.message_throwevent_incoming=self.get_incomings(each_element_of_mf)\n  self.message_throwevent_outgoing=self.get_outgoings(each_element_of_mf)\n  message_throwevent=bpmn_intermediate_messagethrowevent.IntermediateMessageThrowEvent(\n  self.message_throwevent_name,self.message_throwevent_id,\"MessageSend\",\n  self.message_throwevent_incoming,self.message_throwevent_outgoing,\n  self.message_throwevent_configuration)\n  s=json.dumps(message_throwevent.__dict__)\n  self.bpmn_dict[str(each_element_of_mf['id'])]=json.loads(s)\n  \n def _extract_inclusive_gateway_metadata(self,each_element_of_mf):\n  self.inclusive_gateway_name=each_element_of_mf['name']\n  self.inclusive_gateway_id=each_element_of_mf['id']\n  self.inclusive_gateway_configuration=self.get_configuration_properties(\n  each_element_of_mf.bpmn_extensionElements.camunda_properties.camunda_property)\n  self.inclusive_gateway_incoming=self.get_incomings(each_element_of_mf)\n  self.inclusive_gateway_outgoing=self.get_outgoings(each_element_of_mf)\n  inclusive_gateway=bpmn_inclusivegateway.InclusiveGateway(self.inclusive_gateway_name,\n  self.inclusive_gateway_id,\n  \"InclusiveGateway\",\n  self.inclusive_gateway_incoming,\n  self.inclusive_gateway_outgoing,\n  self.inclusive_gateway_configuration)\n  s=json.dumps(inclusive_gateway.__dict__)\n  self.bpmn_dict[str(each_element_of_mf['id'])]=json.loads(s)\n  \n def _extract_msg_start_event_metadata(self,each_element_of_mf):\n  self.start_point_name=each_element_of_mf['name']\n  self.start_point_id=each_element_of_mf['id']\n  self.start_point_configuration__properties=self.get_configuration_properties(\n  each_element_of_mf.bpmn_extensionElements.camunda_properties.camunda_property)\n  self.start_point_outcoming=self.get_outgoings(each_element_of_mf)\n  startpoint=bpmn_messagestartevent.MessageStartEvent(self.start_point_name,self.start_point_id,\n  \"StartEvent\",self.start_point_outcoming,\n  self.start_point_configuration__properties)\n  s=json.dumps(startpoint.__dict__)\n  self.bpmn_dict[str(each_element_of_mf['id'])]=json.loads(s)\n  \n def extract_end_event_metadata(self,each_element_of_mf):\n  self.end_point_name=each_element_of_mf['name']\n  self.end_point_id=each_element_of_mf['id']\n  self.end_point_configuration__properties=self.get_configuration_properties(\n  each_element_of_mf.bpmn_extensionElements.camunda_properties.camunda_property)\n  self.end_point_incoming=self.get_incomings(each_element_of_mf)\n  endpoint=bpmn_endevent.EndEvent(self.end_point_name,self.end_point_id,\"EndEvent\",\n  self.end_point_incoming,self.end_point_configuration__properties)\n  s=json.dumps(endpoint.__dict__)\n  self.bpmn_dict[str(each_element_of_mf['id'])]=json.loads(s)\n  \n def generate_json(self):\n  with open(\"bpmn2json.json\",\"w\")as file:\n   file.write(json.dumps(self.bpmn_dict))\n", ["bpmn_process", "bpmn_process.bpmn_endevent", "bpmn_process.bpmn_inclusivegateway", "bpmn_process.bpmn_intermediate_messagethrowevent", "bpmn_process.bpmn_messageflow", "bpmn_process.bpmn_messagestartevent", "bpmn_process.bpmn_parallelgateway", "bpmn_process.bpmn_servicetask", "json", "untangle"]], "bpmn2camel.bpmn_process.bpmn_endevent": [".py", "class EndEvent:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_incoming=None ,bpmn_outgoing=None ,\n bpmn_configuration_properties=None ):\n  if bpmn_incoming is None :\n   bpmn_incoming=[]\n   \n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.node_type=node_type\n  self.incomings=bpmn_incoming\n  self.outgoings=bpmn_outgoing\n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.configuration_properties=bpmn_configuration_properties\n", []], "bpmn2camel.bpmn_process.bpmn_flows": [".py", "class sequentialFlow:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_configuration_properties=None ):\n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.configuration_properties=bpmn_configuration_properties\n  self.node_type=node_type\n", []], "bpmn2camel.bpmn_process.bpmn_inclusivegateway": [".py", "class InclusiveGateway:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_incoming=None ,bpmn_outgoing=None ,\n bpmn_configuration_properties=None ):\n \n  if bpmn_incoming is None :\n   bpmn_incoming=[]\n   \n  if bpmn_outgoing is None :\n   bpmn_outgoing=[]\n   \n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.incomings=bpmn_incoming\n  self.outgoings=bpmn_outgoing\n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.configuration_properties=bpmn_configuration_properties\n  self.node_type=node_type\n", []], "bpmn2camel.bpmn_process.bpmn_intermediate_messagethrowevent": [".py", "class IntermediateMessageThrowEvent:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_incoming=None ,bpmn_outgoing=None ,\n bpmn_configuration_properties=None ):\n \n  if bpmn_incoming is None :\n   bpmn_incoming=[]\n   \n  if bpmn_outgoing is None :\n   bpmn_outgoing=[]\n   \n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.incomings=bpmn_incoming\n  self.outgoings=bpmn_outgoing\n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.configuration_properties=bpmn_configuration_properties\n  self.node_type=node_type\n", []], "bpmn2camel.bpmn_process.bpmn_messageflow": [".py", "class MessageFlow:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_configuration_properties=None ):\n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.configuration_properties=bpmn_configuration_properties\n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.node_type=node_type\n", []], "bpmn2camel.bpmn_process.bpmn_messagestartevent": [".py", "class MessageStartEvent:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_outgoing=None ,bpmn_configuration_properties=None ):\n \n  if bpmn_outgoing is None :\n   bpmn_outgoing=[]\n   \n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.outgoings=bpmn_outgoing\n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.configuration_properties=bpmn_configuration_properties\n  self.node_type=node_type\n", []], "bpmn2camel.bpmn_process.bpmn_parallelgateway": [".py", "class ParallelGateway:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_incoming=None ,bpmn_outgoing=None ,\n bpmn_configuration_properties=None ):\n \n  if bpmn_incoming is None :\n   bpmn_incoming=[]\n   \n  if bpmn_outgoing is None :\n   bpmn_outgoing=[]\n   \n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.incomings=bpmn_incoming\n  self.outgoings=bpmn_outgoing\n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.configuration_properties=bpmn_configuration_properties\n  self.node_type=node_type\n", []], "bpmn2camel.bpmn_process.bpmn_servicetask": [".py", "class ServiceTask:\n def __init__(self,bpmn_node_name,bpmn_id,node_type,bpmn_incoming=None ,bpmn_outgoing=None ,\n bpmn_configuration_properties=None ):\n \n  if bpmn_incoming is None :\n   bpmn_incoming=[]\n   \n  if bpmn_outgoing is None :\n   bpmn_outgoing=[]\n   \n  if bpmn_configuration_properties is None :\n   bpmn_configuration_properties={}\n   \n  self.incomings=bpmn_incoming\n  self.outgoings=bpmn_outgoing\n  self.node_name=bpmn_node_name\n  self.id=bpmn_id\n  self.configuration_properties=bpmn_configuration_properties\n  self.node_type=node_type\n", []], "bpmn2camel.bpmn_process.untangle": [".py", "#!/usr/bin/env python\n\n\"\"\"\n untangle\n\n Converts xml to python objects.\n\n The only method you need to call is parse()\n\n Partially inspired by xml2obj\n (http://code.activestate.com/recipes/149368-xml2obj/)\n\n Author: Christian Stefanescu (http://0chris.com)\n License: MIT License - http://www.opensource.org/licenses/mit-license.php\n\"\"\"\nimport os\nfrom xml.sax import make_parser,handler\ntry :\n from StringIO import StringIO\nexcept ImportError:\n from io import StringIO\ntry :\n from types import StringTypes\n is_string=lambda x:isinstance(x,StringTypes)\nexcept ImportError:\n is_string=lambda x:isinstance(x,str)\n \n__version__='1.1.1'\n\n\nclass Element(object):\n ''\n\n \n def __init__(self,name,attributes):\n  self._name=name\n  self._attributes=attributes\n  self.children=[]\n  self.is_root=False\n  self.cdata=''\n  \n def add_child(self,element):\n  ''\n\n  \n  self.children.append(element)\n  \n def add_cdata(self,cdata):\n  ''\n\n  \n  self.cdata=self.cdata+cdata\n  \n def get_attribute(self,key):\n  ''\n\n  \n  return self._attributes.get(key)\n  \n def get_elements(self,name=None ):\n  ''\n\n  \n  if name:\n   return [e for e in self.children if e._name ==name]\n  else :\n   return self.children\n   \n def __getitem__(self,key):\n  return self.get_attribute(key)\n  \n def __getattr__(self,key):\n  matching_children=[x for x in self.children if x._name ==key]\n  if matching_children:\n   if len(matching_children)==1:\n    self.__dict__[key]=matching_children[0]\n    return matching_children[0]\n   else :\n    self.__dict__[key]=matching_children\n    return matching_children\n  else :\n   raise AttributeError(\n   \"'%s' has no attribute '%s'\"%(self._name,key)\n   )\n   \n def __hasattribute__(self,name):\n  if name in self.__dict__:\n   return True\n  return any(self.children,lambda x:x._name ==name)\n  \n def __iter__(self):\n  yield self\n  \n def __str__(self):\n  return (\n  \"Element <%s> with attributes %s, children %s and cdata %s\"%\n  (self._name,self._attributes,self.children,self.cdata)\n  )\n  \n def __repr__(self):\n  return (\n  \"Element(name = %s, attributes = %s, cdata = %s)\"%\n  (self._name,self._attributes,self.cdata)\n  )\n  \n def __nonzero__(self):\n  return self.is_root or self._name is not None\n  \n def __eq__(self,val):\n  return self.cdata ==val\n  \n def __dir__(self):\n  children_names=[x._name for x in self.children]\n  return children_names\n  \n def __len__(self):\n  return len(self.children)\n  \n  \nclass Handler(handler.ContentHandler):\n ''\n\n \n def __init__(self):\n  self.root=Element(None ,None )\n  self.root.is_root=True\n  self.elements=[]\n  \n def startElement(self,name,attributes):\n  name=name.replace('-','_')\n  name=name.replace('.','_')\n  name=name.replace(':','_')\n  attrs=dict()\n  for k,v in attributes.items():\n   attrs[k]=v\n  element=Element(name,attrs)\n  if len(self.elements)>0:\n   self.elements[-1].add_child(element)\n  else :\n   self.root.add_child(element)\n  self.elements.append(element)\n  \n def endElement(self,name):\n  self.elements.pop()\n  \n def characters(self,cdata):\n  self.elements[-1].add_cdata(cdata)\n  \n  \ndef parse(filename,**parser_features):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n if (filename is None or (is_string(filename)and filename.strip())==''):\n  raise ValueError('parse() takes a filename, URL or XML string')\n parser=make_parser()\n for feature,value in parser_features.items():\n  parser.setFeature(getattr(handler,feature),value)\n sax_handler=Handler()\n parser.setContentHandler(sax_handler)\n if is_string(filename)and (os.path.exists(filename)or is_url(filename)):\n  parser.parse(filename)\n else :\n  if hasattr(filename,'read'):\n   parser.parse(filename)\n  else :\n   parser.parse(StringIO(filename))\n   \n return sax_handler.root\n \n \ndef is_url(string):\n ''\n\n \n try :\n  return string.startswith('http://')or string.startswith('https://')\n except AttributeError:\n  return False\n  \n  \n", ["StringIO", "io", "os", "types", "xml.sax"]], "bpmn2camel.bpmn_process": [".py", "", [], 1], "bpmn2camel.camel_dsl.extract_elements_from_json": [".py", "import json\n\nfrom .Json2Camel import ServiceTask2Camel\nfrom .Json2Camel import ServiceTask2CamelRouteXML\nfrom .Json2Camel import MessageStartEvent2Camel\nfrom .Json2Camel import MessageStartEvent2CamelRouteXML\nfrom .Json2Camel import ParallelGateway2Camel\nfrom .Json2Camel import ParallelGateway2CamelRouteXML\nfrom .Json2Camel import EndEvent2Camel\nfrom .Json2Camel import EndEvent2CamelRouteXML\nfrom camel_dsl.Json2Camel import InclusiveGateway2Camel\nfrom camel_dsl.Json2Camel import InclusiveGateway2CamelRouteXML\nfrom camel_dsl.Json2Camel import MessageFlow2Camel\nfrom camel_dsl.Json2Camel import MessageFlow2CamelRouteXML\n\n\n\njson_file=\"bpmn2json.json\"\n\n\nclass JsonUtil:\n def load_elements(self):\n  with open(json_file)as file:\n   self.loaded_json={}\n   bpmn_elements=file.read()\n   self.loaded_json=json.loads(bpmn_elements)\n   for x in self.loaded_json:\n    pass\n    \n  return self.loaded_json\n  \n def from_uri(self,bpmn_ref_incomings,multiple_uri=False ):\n \n  if multiple_uri:\n   from_uris=[]\n   for each_from_uri in bpmn_ref_incomings:\n    from_uris.append(\"seda:\"+each_from_uri)\n   return from_uris\n   \n  else :\n   incoming=bpmn_ref_incomings[0]\n   from_uri=\"seda:\"+incoming\n   return from_uri\n   \n def from_source(self,msg_source):\n  from_uri='activemq:'+'my_queue'\n  return from_uri\n  \n def to_uri(self,bpmn_ref_outgoings):\n  outgoing=bpmn_ref_outgoings[0]\n  to_uri=\"seda:\"+outgoing\n  return to_uri\n  \n def multiple_receipients(self,bpmn_ref_outgoings):\n  mul_receipients={}\n  bpmn_ref_outgoings_with_queues=[]\n  use_queue=\"seda:\"\n  for each_value in bpmn_ref_outgoings:\n   bpmn_ref_outgoings_with_queues.append(use_queue+each_value)\n  mul_receipients[\"multicast\"]=bpmn_ref_outgoings_with_queues\n  return mul_receipients\n  \n def process_to_execute(self,bpmn_ref_process):\n  process_to_execute=bpmn_ref_process\n  return process_to_execute\n  \n def find_camel_elements(self):\n \n  camel_elements=self.load_elements()\n  for each_key,each_value in camel_elements.items():\n  \n  \n  \n   if each_value['node_type']==\"ServiceTask\":\n    serviceTask2Camel=ServiceTask2Camel.ServiceTask2Camel(self.from_uri(each_value['incomings']),\n    self.to_uri(each_value['outgoings']),\n    self.process_to_execute(each_value['node_name'])\n    )\n    gen_servicetask_route=ServiceTask2CamelRouteXML.ServiceTask2CamelRouteXML(serviceTask2Camel)\n    \n    \n   if each_value['node_type']==\"StartEvent\":\n    messageStartEvent2Camel=MessageStartEvent2Camel.MessageStartEvent2Camel(self.from_source('my_queue'),\n    self.to_uri(\n    each_value['outgoings']))\n    gen_message_start_event_route=MessageStartEvent2CamelRouteXML.MessageStartEvent2CamelRouteXML(\n    messageStartEvent2Camel)\n    \n    \n   if each_value['node_type']==\"ParallelGateway\":\n    parallelGateway2Camel=ParallelGateway2Camel.ParallelGateway2Camel(\n    self.from_uri(each_value['incomings']),\n    self.multiple_receipients(\n    each_value['outgoings']))\n    gen_parallel_gateway_route=ParallelGateway2CamelRouteXML.ParallelGateway2CamelRouteXML(\n    parallelGateway2Camel)\n    \n    \n   if each_value['node_type']==\"InclusiveGateway\":\n    inclusiveGateway2Camel=InclusiveGateway2Camel.InclusiveGateway2Camel(\n    self.from_uri(each_value['incomings'],multiple_uri=True ),\n    each_value['id'],self.to_uri(each_value['outgoings']))\n    gen_inclusive_gateway_route=InclusiveGateway2CamelRouteXML.InclusiveGateway2CamelRouteXML(\n    inclusiveGateway2Camel)\n    \n    \n    \n   if each_value['node_type']==\"EndEvent\":\n    endEvent2Camel=EndEvent2Camel.EndEvent2Camel(self.from_uri(each_value['incomings']))\n    gen_end_event_route=EndEvent2CamelRouteXML.EndEvent2CamelRouteXML(\n    endEvent2Camel)\n    \n    \n   if each_value['node_type']==\"MessageFlow\":\n    messageFlow2Camel=MessageFlow2Camel.MessageFlow2Camel(each_value['id'],each_value['node_name'],\n    each_value['node_type'])\n    gen_message_flow_route=MessageFlow2CamelRouteXML.MessageFlow2CamelRouteXML(\n    messageFlow2Camel)\n    \n", ["bpmn2camel.camel_dsl.Json2Camel", "camel_dsl.Json2Camel", "camel_dsl.Json2Camel.InclusiveGateway2Camel", "camel_dsl.Json2Camel.InclusiveGateway2CamelRouteXML", "camel_dsl.Json2Camel.MessageFlow2Camel", "camel_dsl.Json2Camel.MessageFlow2CamelRouteXML", "json"]], "bpmn2camel.camel_dsl": [".py", "", [], 1], "bpmn2camel.camel_dsl.Json2Camel.EndEvent2Camel": [".py", "import collections\nclass EndEvent2Camel:\n def __init__(self,from_uri):\n  self.from_uri=from_uri\n  self.to_uri=\"seda:outbound\"\n  self.process_to_execute=\"outbound_process\"\n  \n def get_routes_as_dict(self):\n  end_event_as_dict=collections.OrderedDict()\n  end_event_as_dict['from']=self.from_uri\n  end_event_as_dict['process']=self.process_to_execute\n  end_event_as_dict['to']=self.to_uri\n  return end_event_as_dict\n", ["collections"]], "bpmn2camel.camel_dsl.Json2Camel.EndEvent2CamelRouteXML": [".py", "from datetime import datetime\n\nfrom camel_dsl.Json2Camel.Json2CamelUtil import Json2CamelUtil\n\n\nclass EndEvent2CamelRouteXML:\n def __init__(self,endEvent2Camel):\n  self.endEvent2Camel=endEvent2Camel\n  \n def save_endevent_routes(self):\n  jcu=Json2CamelUtil(self.endEvent2Camel)\n  xml2file=jcu.data2xml()\n  with open('endevent_routes'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.xml','a')as file:\n   file.write(xml2file)\n   file.write(\"\\n\")\n  return xml2file\n  \n", ["camel_dsl.Json2Camel.Json2CamelUtil", "datetime"]], "bpmn2camel.camel_dsl.Json2Camel.InclusiveGateway2Camel": [".py", "import collections\nclass InclusiveGateway2Camel:\n def __init__(self,from_uri,node_id,to_uri):\n  self.from_uri=from_uri\n  self.to_uri=to_uri\n  self.intermediate_inclusive_gateway_queue=\"seda:\"+node_id\n  \n def get_routes_as_dict(self):\n  in_routes_as_list_of_dict=[]\n  for each_from_uri in self.from_uri:\n   in_routes_as_list_of_dict.append(self._get_in_route_as_dict(each_from_uri))\n  in_routes_as_list_of_dict.append(self._get_out_route_as_dict())\n  return in_routes_as_list_of_dict\n  \n def _get_in_route_as_dict(self,each_from_uri):\n  inclusive_gatewawy_in_routes=collections.OrderedDict()\n  inclusive_gatewawy_in_routes['from']=each_from_uri\n  inclusive_gatewawy_in_routes['to']=self.intermediate_inclusive_gateway_queue\n  return inclusive_gatewawy_in_routes\n  \n def _get_out_route_as_dict(self):\n  completion_size=len(self.from_uri)\n  inclusive_gatewawy_out_routes=collections.OrderedDict()\n  inclusive_gatewawy_out_routes['from']=self.intermediate_inclusive_gateway_queue\n  inclusive_gatewawy_out_routes['aggregate']=completion_size\n  inclusive_gatewawy_out_routes['to']=self.to_uri\n  return inclusive_gatewawy_out_routes\n", ["collections"]], "bpmn2camel.camel_dsl.Json2Camel.InclusiveGateway2CamelRouteXML": [".py", "from datetime import datetime\n\nfrom camel_dsl.Json2Camel.Json2CamelUtil import Json2CamelUtil\n\n\nclass InclusiveGateway2CamelRouteXML:\n def __init__(self,inclusveGateway2Camel):\n  self.inclusveGateway2Camel=inclusveGateway2Camel\n  \n def save_inclusivegateways_input_routes(self):\n  jcu=Json2CamelUtil(self.inclusveGateway2Camel)\n  xml2file=jcu.data2xml(multiple_dict=True )\n  with open('inclusive_gateway_input_routes'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.xml','a')as file:\n   for each_route in xml2file:\n    file.write(each_route)\n    file.write(\"\\n\")\n  return xml2file\n", ["camel_dsl.Json2Camel.Json2CamelUtil", "datetime"]], "bpmn2camel.camel_dsl.Json2Camel.Json2CamelUtil": [".py", "import lxml.etree as et\nfrom datetime import datetime\nfrom operator import attrgetter\nimport collections\n\n\n\n\nclass Json2CamelUtil:\n camel_route=[]\n camel_sub_routes=[]\n \n def __init__(self,element2camel):\n  self.element2camel=element2camel\n  \n def data2xml(self,multiple_dict=None ,name='route'):\n  route=et.Element(name)\n  xml2file=[]\n  if multiple_dict ==True :\n   for each_dict in self.element2camel.get_routes_as_dict():\n    route=et.Element(name)\n    route_as_string=et.tostring(self.buildxml(route,each_dict))\n    self.generate_camel_route(route,route_as_string)\n    xml2file.append(route_as_string)\n   return xml2file\n  else :\n   route_as_string=et.tostring(self.buildxml(route,self.element2camel.get_routes_as_dict()))\n   self.generate_camel_route(route,route_as_string)\n   return route_as_string\n   \n def buildxml(self,route,xml_ele):\n  stc=xml_ele\n  if isinstance(stc,dict)or isinstance(stc,collections.OrderedDict):\n   for each_key,each_value in stc.items():\n    s=et.SubElement(route,each_key)\n    self.buildxml(s,each_value)\n  elif isinstance(stc,tuple)or isinstance(stc,list):\n   for each_value_of_element2camel in stc:\n    s=et.SubElement(route,'to')\n    self.buildxml(s,each_value_of_element2camel)\n    \n    \n  elif isinstance(stc,str):\n   self._handle_attribute(route,stc)\n  else :\n   self._handle_attribute(route,stc)\n  return route\n  \n def _handle_attribute(self,route,stc):\n  if route.tag =='from':\n   route.set('uri',stc)\n   \n  elif route.tag =='to':\n   route.set('uri',stc)\n   \n  elif route.tag =='process':\n   route.set('ref',stc)\n   \n  elif route.tag =='aggregate':\n   route.set('strategyRef','myAggregationStrategy')\n   route.set('completionSize',str(stc).decode(\"utf-8\"))\n   correlation_exp_element=et.SubElement(route,'correlationExpression')\n   header_element=et.SubElement(correlation_exp_element,'header')\n   header_element.text='EXCHANGE_ID'\n   \n  else :\n   route.text=stc\n   \n def generate_camel_route(self,route,route_as_string):\n  root=et.fromstring(route_as_string)\n  if root.tag =='route':\n   Json2CamelUtil.camel_sub_routes.append(route)\n  if root.tag =='routes':\n   Json2CamelUtil.camel_route.append(route)\n  if len(Json2CamelUtil.camel_route)==1:\n   for each_route_defined in Json2CamelUtil.camel_sub_routes:\n    lang=et.ElementTree(Json2CamelUtil.camel_route[0])\n    routes=lang.getroot()\n    routes.append(each_route_defined)\n    Json2CamelUtil.camel_route=[]\n    Json2CamelUtil.camel_route.append(routes)\n    \n   root=Json2CamelUtil.camel_route[0]\n   save_route=et.tostring(root).decode(\"utf-8\")\n   self.save_camel_routes(save_route)\n   \n def save_camel_routes(self,save_to_file):\n  with open('camel_route'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.xml','w+')as file:\n   file.write(save_to_file)\n   file.write(\"\\n\")\n", ["collections", "datetime", "lxml.etree", "operator"]], "bpmn2camel.camel_dsl.Json2Camel.MessageFlow2Camel": [".py", "import json\n\n\nclass MessageFlow2Camel:\n def __init__(self,node_id,node_name,node_type):\n  self.id=node_id\n  self.node_name=node_name\n  self.node_type=node_type\n  \n def get_routes_as_dict(self):\n  return {\"description\":json.dumps(\n  {\"routeId\":self.id,\"displayName\":self.node_name,\"description\":self.node_type+self.node_name})}\n", ["json"]], "bpmn2camel.camel_dsl.Json2Camel.MessageFlow2CamelRouteXML": [".py", "from datetime import datetime\n\nfrom camel_dsl.Json2Camel.Json2CamelUtil import Json2CamelUtil\n\n\nclass MessageFlow2CamelRouteXML:\n def __init__(self,messageFlow2Camel):\n  self.messageFlow2Camel=messageFlow2Camel\n  \n def save_messageflow_routes(self):\n  jcu=Json2CamelUtil(self.messageFlow2Camel)\n  xml2file=jcu.data2xml(name=\"routes\")\n  with open('messageflow_routes'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.xml','ab')as file:\n   file.write(xml2file)\n   \n  return xml2file\n", ["camel_dsl.Json2Camel.Json2CamelUtil", "datetime"]], "bpmn2camel.camel_dsl.Json2Camel.MessageStartEvent2Camel": [".py", "import collections\nclass MessageStartEvent2Camel:\n def __init__(self,from_uri,to_uri):\n  self.from_uri=from_uri\n  self.to_uri=to_uri\n  \n def get_routes_as_dict(self):\n  message_start_event_as_dict=collections.OrderedDict()\n  message_start_event_as_dict['from']=self.from_uri\n  message_start_event_as_dict['to']=self.to_uri\n  return message_start_event_as_dict\n", ["collections"]], "bpmn2camel.camel_dsl.Json2Camel.MessageStartEvent2CamelRouteXML": [".py", "from datetime import datetime\nfrom camel_dsl.Json2Camel.Json2CamelUtil import Json2CamelUtil\n\n\nclass MessageStartEvent2CamelRouteXML:\n def __init__(self,messageStartEvent2Camel):\n  self.messageStartEvent2Camel=messageStartEvent2Camel\n  \n def save_message_start_event_routes(self):\n  jcu=Json2CamelUtil(self.messageStartEvent2Camel)\n  xml2file=jcu.data2xml()\n  with open('messagestartevent_routes'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.xml','a')as file:\n   file.write(xml2file)\n   file.write(\"\\n\")\n  return xml2file\n", ["camel_dsl.Json2Camel.Json2CamelUtil", "datetime"]], "bpmn2camel.camel_dsl.Json2Camel.ParallelGateway2Camel": [".py", "import collections\nclass ParallelGateway2Camel:\n def __init__(self,from_uri,multicast=None ):\n  self.from_uri=from_uri\n  \n  if multicast is None :\n   multicast={}\n   \n  self.multicast_receipients=multicast\n  \n def _get_from_uri_as_dict(self):\n  parallelgateway_as_dict_fromuri={'from':self.from_uri}\n  return parallelgateway_as_dict_fromuri\n  \n def _get__multicast_as_dict(self):\n  return self.multicast_receipients\n  \n def get_routes_as_dict(self):\n  parallel_gateway_as_dict=collections.OrderedDict()\n  \n  x=self._get_from_uri_as_dict()\n  y=self._get__multicast_as_dict()\n  \n  parallel_gateway_as_dict.update(x.copy())\n  parallel_gateway_as_dict.update(y)\n  \n  \n  return parallel_gateway_as_dict\n", ["collections"]], "bpmn2camel.camel_dsl.Json2Camel.ParallelGateway2CamelRouteXML": [".py", "from datetime import datetime\n\nfrom camel_dsl.Json2Camel.Json2CamelUtil import Json2CamelUtil\n\n\nclass ParallelGateway2CamelRouteXML:\n def __init__(self,parallelGateway2Camel):\n  self.parallelGateway2Camel=parallelGateway2Camel\n  \n def save_parallelgateway_routes(self):\n  jcu=Json2CamelUtil(self.parallelGateway2Camel)\n  xml2file=jcu.data2xml()\n  with open('parallel_gateway'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.xml','a')as file:\n   file.write(xml2file)\n   file.write(\"\\n\")\n  return xml2file\n", ["camel_dsl.Json2Camel.Json2CamelUtil", "datetime"]], "bpmn2camel.camel_dsl.Json2Camel.ServiceTask2Camel": [".py", "import collections\n\nclass ServiceTask2Camel:\n\n def __init__(self,from_uri,to_uri,process_to_execute):\n  self.from_uri=from_uri\n  self.to_uri=to_uri\n  self.process_to_execute=process_to_execute\n  \n def get_routes_as_dict(self):\n  servicetask_as_dict=collections.OrderedDict()\n  servicetask_as_dict['from']=self.from_uri\n  servicetask_as_dict['process']=self.process_to_execute\n  servicetask_as_dict['to']=self.to_uri\n  return servicetask_as_dict\n", ["collections"]], "bpmn2camel.camel_dsl.Json2Camel.ServiceTask2CamelRouteXML": [".py", "from datetime import datetime\n\nfrom camel_dsl.Json2Camel.Json2CamelUtil import Json2CamelUtil\n\nclass ServiceTask2CamelRouteXML:\n def __init__(self,serviceTask2Camel):\n  self.serviceTask2Camel=serviceTask2Camel\n  \n def save_servicetask_routes(self):\n  jcu=Json2CamelUtil(self.serviceTask2Camel)\n  xml2file=jcu.data2xml()\n  with open('servicetask_routes'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.xml','a')as file:\n   file.write(xml2file)\n   file.write(\"\\n\")\n  return xml2file\n", ["camel_dsl.Json2Camel.Json2CamelUtil", "datetime"]], "bpmn2camel.camel_dsl.Json2Camel": [".py", "", [], 1], "bpmn2camel.camel_dsl.Json2Camel.lxml.builder": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\"\nThe ``E`` Element factory for generating XML documents.\n\"\"\"\n\nfrom __future__ import absolute_import\n\nimport lxml.etree as ET\n\nfrom functools import partial\n\ntry :\n basestring\nexcept NameError:\n basestring=str\n \ntry :\n unicode\nexcept NameError:\n unicode=str\n \n \nclass ElementMaker(object):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n def __init__(self,typemap=None ,\n namespace=None ,nsmap=None ,makeelement=None ):\n  if namespace is not None :\n   self._namespace='{'+namespace+'}'\n  else :\n   self._namespace=None\n   \n  if nsmap:\n   self._nsmap=dict(nsmap)\n  else :\n   self._nsmap=None\n   \n  if makeelement is not None :\n   assert callable(makeelement)\n   self._makeelement=makeelement\n  else :\n   self._makeelement=ET.Element\n   \n   \n   \n  if typemap:\n   typemap=dict(typemap)\n  else :\n   typemap={}\n   \n  def add_text(elem,item):\n   try :\n    elem[-1].tail=(elem[-1].tail or \"\")+item\n   except IndexError:\n    elem.text=(elem.text or \"\")+item\n    \n  def add_cdata(elem,cdata):\n   if elem.text:\n    raise ValueError(\"Can't add a CDATA section. Element already has some text: %r\"%elem.text)\n   elem.text=cdata\n   \n  if str not in typemap:\n   typemap[str]=add_text\n  if unicode not in typemap:\n   typemap[unicode]=add_text\n  if ET.CDATA not in typemap:\n   typemap[ET.CDATA]=add_cdata\n   \n  def add_dict(elem,item):\n   attrib=elem.attrib\n   for k,v in item.items():\n    if isinstance(v,basestring):\n     attrib[k]=v\n    else :\n     attrib[k]=typemap[type(v)](None ,v)\n  if dict not in typemap:\n   typemap[dict]=add_dict\n   \n  self._typemap=typemap\n  \n def __call__(self,tag,*children,**attrib):\n  typemap=self._typemap\n  \n  if self._namespace is not None and tag[0]!='{':\n   tag=self._namespace+tag\n  elem=self._makeelement(tag,nsmap=self._nsmap)\n  if attrib:\n   typemap[dict](elem,attrib)\n   \n  for item in children:\n   if callable(item):\n    item=item()\n   t=typemap.get(type(item))\n   if t is None :\n    if ET.iselement(item):\n     elem.append(item)\n     continue\n    for basetype in type(item).__mro__:\n    \n     t=typemap.get(basetype)\n     if t is not None :\n      break\n    else :\n     raise TypeError(\"bad argument type: %s(%r)\"%\n     (type(item).__name__,item))\n   v=t(elem,item)\n   if v:\n    typemap.get(type(v))(elem,v)\n    \n  return elem\n  \n def __getattr__(self,tag):\n  return partial(self,tag)\n  \n  \n  \nE=ElementMaker()\n", ["__future__", "functools", "lxml.etree"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.cssselect": [".py", "''\n\n\n\n\n\n\n\nfrom __future__ import absolute_import\n\nfrom . import etree\ntry :\n import cssselect as external_cssselect\nexcept ImportError:\n raise ImportError(\n 'cssselect does not seem to be installed. '\n 'See http://packages.python.org/cssselect/')\n \n \nSelectorSyntaxError=external_cssselect.SelectorSyntaxError\nExpressionError=external_cssselect.ExpressionError\nSelectorError=external_cssselect.SelectorError\n\n\n__all__=['SelectorSyntaxError','ExpressionError','SelectorError',\n'CSSSelector']\n\n\nclass LxmlTranslator(external_cssselect.GenericTranslator):\n ''\n\n \n def xpath_contains_function(self,xpath,function):\n \n \n  if function.argument_types()not in (['STRING'],['IDENT']):\n   raise ExpressionError(\n   \"Expected a single string or ident for :contains(), got %r\"\n   %function.arguments)\n  value=function.arguments[0].value\n  return xpath.add_condition(\n  'contains(__lxml_internal_css:lower-case(string(.)), %s)'\n  %self.xpath_literal(value.lower()))\n  \n  \nclass LxmlHTMLTranslator(LxmlTranslator,external_cssselect.HTMLTranslator):\n ''\n\n \n \n \ndef _make_lower_case(context,s):\n return s.lower()\n \nns=etree.FunctionNamespace('http://codespeak.net/lxml/css/')\nns.prefix='__lxml_internal_css'\nns['lower-case']=_make_lower_case\n\n\nclass CSSSelector(etree.XPath):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n def __init__(self,css,namespaces=None ,translator='xml'):\n  if translator =='xml':\n   translator=LxmlTranslator()\n  elif translator =='html':\n   translator=LxmlHTMLTranslator()\n  elif translator =='xhtml':\n   translator=LxmlHTMLTranslator(xhtml=True )\n  path=translator.css_to_xpath(css)\n  etree.XPath.__init__(self,path,namespaces=namespaces)\n  self.css=css\n  \n def __repr__(self):\n  return '<%s %s for %r>'%(\n  self.__class__.__name__,\n  hex(abs(id(self)))[2:],\n  self.css)\n", ["__future__", "bpmn2camel.camel_dsl.Json2Camel.lxml", "cssselect"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.doctestcompare": [".py", "''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom lxml import etree\nimport sys\nimport re\nimport doctest\ntry :\n from html import escape as html_escape\nexcept ImportError:\n from cgi import escape as html_escape\n \n__all__=['PARSE_HTML','PARSE_XML','NOPARSE_MARKUP','LXMLOutputChecker',\n'LHTMLOutputChecker','install','temp_install']\n\ntry :\n _basestring=basestring\nexcept NameError:\n _basestring=(str,bytes)\n \n_IS_PYTHON_3=sys.version_info[0]>=3\n\nPARSE_HTML=doctest.register_optionflag('PARSE_HTML')\nPARSE_XML=doctest.register_optionflag('PARSE_XML')\nNOPARSE_MARKUP=doctest.register_optionflag('NOPARSE_MARKUP')\n\nOutputChecker=doctest.OutputChecker\n\ndef strip(v):\n if v is None :\n  return None\n else :\n  return v.strip()\n  \ndef norm_whitespace(v):\n return _norm_whitespace_re.sub(' ',v)\n \n_html_parser=etree.HTMLParser(recover=False ,remove_blank_text=True )\n\ndef html_fromstring(html):\n return etree.fromstring(html,_html_parser)\n \n \n_repr_re=re.compile(r'^<[^>]+ (at|object) ')\n_norm_whitespace_re=re.compile(r'[ \\t\\n][ \\t\\n]+')\n\nclass LXMLOutputChecker(OutputChecker):\n\n empty_tags=(\n 'param','img','area','br','basefont','input',\n 'base','meta','link','col')\n \n def get_default_parser(self):\n  return etree.XML\n  \n def check_output(self,want,got,optionflags):\n  alt_self=getattr(self,'_temp_override_self',None )\n  if alt_self is not None :\n   super_method=self._temp_call_super_check_output\n   self=alt_self\n  else :\n   super_method=OutputChecker.check_output\n  parser=self.get_parser(want,got,optionflags)\n  if not parser:\n   return super_method(\n   self,want,got,optionflags)\n  try :\n   want_doc=parser(want)\n  except etree.XMLSyntaxError:\n   return False\n  try :\n   got_doc=parser(got)\n  except etree.XMLSyntaxError:\n   return False\n  return self.compare_docs(want_doc,got_doc)\n  \n def get_parser(self,want,got,optionflags):\n  parser=None\n  if NOPARSE_MARKUP&optionflags:\n   return None\n  if PARSE_HTML&optionflags:\n   parser=html_fromstring\n  elif PARSE_XML&optionflags:\n   parser=etree.XML\n  elif (want.strip().lower().startswith('<html')\n  and got.strip().startswith('<html')):\n   parser=html_fromstring\n  elif (self._looks_like_markup(want)\n  and self._looks_like_markup(got)):\n   parser=self.get_default_parser()\n  return parser\n  \n def _looks_like_markup(self,s):\n  s=s.strip()\n  return (s.startswith('<')\n  and not _repr_re.search(s))\n  \n def compare_docs(self,want,got):\n  if not self.tag_compare(want.tag,got.tag):\n   return False\n  if not self.text_compare(want.text,got.text,True ):\n   return False\n  if not self.text_compare(want.tail,got.tail,True ):\n   return False\n  if 'any'not in want.attrib:\n   want_keys=sorted(want.attrib.keys())\n   got_keys=sorted(got.attrib.keys())\n   if want_keys !=got_keys:\n    return False\n   for key in want_keys:\n    if not self.text_compare(want.attrib[key],got.attrib[key],False ):\n     return False\n  if want.text !='...'or len(want):\n   want_children=list(want)\n   got_children=list(got)\n   while want_children or got_children:\n    if not want_children or not got_children:\n     return False\n    want_first=want_children.pop(0)\n    got_first=got_children.pop(0)\n    if not self.compare_docs(want_first,got_first):\n     return False\n    if not got_children and want_first.tail =='...':\n     break\n  return True\n  \n def text_compare(self,want,got,strip):\n  want=want or ''\n  got=got or ''\n  if strip:\n   want=norm_whitespace(want).strip()\n   got=norm_whitespace(got).strip()\n  want='^%s$'%re.escape(want)\n  want=want.replace(r'\\.\\.\\.','.*')\n  if re.search(want,got):\n   return True\n  else :\n   return False\n   \n def tag_compare(self,want,got):\n  if want =='any':\n   return True\n  if (not isinstance(want,_basestring)\n  or not isinstance(got,_basestring)):\n   return want ==got\n  want=want or ''\n  got=got or ''\n  if want.startswith('{...}'):\n  \n   return want.split('}')[-1]==got.split('}')[-1]\n  else :\n   return want ==got\n   \n def output_difference(self,example,got,optionflags):\n  want=example.want\n  parser=self.get_parser(want,got,optionflags)\n  errors=[]\n  if parser is not None :\n   try :\n    want_doc=parser(want)\n   except etree.XMLSyntaxError:\n    e=sys.exc_info()[1]\n    errors.append('In example: %s'%e)\n   try :\n    got_doc=parser(got)\n   except etree.XMLSyntaxError:\n    e=sys.exc_info()[1]\n    errors.append('In actual output: %s'%e)\n  if parser is None or errors:\n   value=OutputChecker.output_difference(\n   self,example,got,optionflags)\n   if errors:\n    errors.append(value)\n    return '\\n'.join(errors)\n   else :\n    return value\n  html=parser is html_fromstring\n  diff_parts=['Expected:',\n  self.format_doc(want_doc,html,2),\n  'Got:',\n  self.format_doc(got_doc,html,2),\n  'Diff:',\n  self.collect_diff(want_doc,got_doc,html,2)]\n  return '\\n'.join(diff_parts)\n  \n def html_empty_tag(self,el,html=True ):\n  if not html:\n   return False\n  if el.tag not in self.empty_tags:\n   return False\n  if el.text or len(el):\n  \n   return False\n  return True\n  \n def format_doc(self,doc,html,indent,prefix=''):\n  parts=[]\n  if not len(doc):\n  \n   parts.append(' '*indent)\n   parts.append(prefix)\n   parts.append(self.format_tag(doc))\n   if not self.html_empty_tag(doc,html):\n    if strip(doc.text):\n     parts.append(self.format_text(doc.text))\n    parts.append(self.format_end_tag(doc))\n   if strip(doc.tail):\n    parts.append(self.format_text(doc.tail))\n   parts.append('\\n')\n   return ''.join(parts)\n  parts.append(' '*indent)\n  parts.append(prefix)\n  parts.append(self.format_tag(doc))\n  if not self.html_empty_tag(doc,html):\n   parts.append('\\n')\n   if strip(doc.text):\n    parts.append(' '*indent)\n    parts.append(self.format_text(doc.text))\n    parts.append('\\n')\n   for el in doc:\n    parts.append(self.format_doc(el,html,indent+2))\n   parts.append(' '*indent)\n   parts.append(self.format_end_tag(doc))\n   parts.append('\\n')\n  if strip(doc.tail):\n   parts.append(' '*indent)\n   parts.append(self.format_text(doc.tail))\n   parts.append('\\n')\n  return ''.join(parts)\n  \n def format_text(self,text,strip=True ):\n  if text is None :\n   return ''\n  if strip:\n   text=text.strip()\n  return html_escape(text,1)\n  \n def format_tag(self,el):\n  attrs=[]\n  if isinstance(el,etree.CommentBase):\n  \n   return '<!--'\n  for name,value in sorted(el.attrib.items()):\n   attrs.append('%s=\"%s\"'%(name,self.format_text(value,False )))\n  if not attrs:\n   return '<%s>'%el.tag\n  return '<%s %s>'%(el.tag,' '.join(attrs))\n  \n def format_end_tag(self,el):\n  if isinstance(el,etree.CommentBase):\n  \n   return '-->'\n  return '</%s>'%el.tag\n  \n def collect_diff(self,want,got,html,indent):\n  parts=[]\n  if not len(want)and not len(got):\n   parts.append(' '*indent)\n   parts.append(self.collect_diff_tag(want,got))\n   if not self.html_empty_tag(got,html):\n    parts.append(self.collect_diff_text(want.text,got.text))\n    parts.append(self.collect_diff_end_tag(want,got))\n   parts.append(self.collect_diff_text(want.tail,got.tail))\n   parts.append('\\n')\n   return ''.join(parts)\n  parts.append(' '*indent)\n  parts.append(self.collect_diff_tag(want,got))\n  parts.append('\\n')\n  if strip(want.text)or strip(got.text):\n   parts.append(' '*indent)\n   parts.append(self.collect_diff_text(want.text,got.text))\n   parts.append('\\n')\n  want_children=list(want)\n  got_children=list(got)\n  while want_children or got_children:\n   if not want_children:\n    parts.append(self.format_doc(got_children.pop(0),html,indent+2,'+'))\n    continue\n   if not got_children:\n    parts.append(self.format_doc(want_children.pop(0),html,indent+2,'-'))\n    continue\n   parts.append(self.collect_diff(\n   want_children.pop(0),got_children.pop(0),html,indent+2))\n  parts.append(' '*indent)\n  parts.append(self.collect_diff_end_tag(want,got))\n  parts.append('\\n')\n  if strip(want.tail)or strip(got.tail):\n   parts.append(' '*indent)\n   parts.append(self.collect_diff_text(want.tail,got.tail))\n   parts.append('\\n')\n  return ''.join(parts)\n  \n def collect_diff_tag(self,want,got):\n  if not self.tag_compare(want.tag,got.tag):\n   tag='%s (got: %s)'%(want.tag,got.tag)\n  else :\n   tag=got.tag\n  attrs=[]\n  any=want.tag =='any'or 'any'in want.attrib\n  for name,value in sorted(got.attrib.items()):\n   if name not in want.attrib and not any:\n    attrs.append('+%s=\"%s\"'%(name,self.format_text(value,False )))\n   else :\n    if name in want.attrib:\n     text=self.collect_diff_text(want.attrib[name],value,False )\n    else :\n     text=self.format_text(value,False )\n    attrs.append('%s=\"%s\"'%(name,text))\n  if not any:\n   for name,value in sorted(want.attrib.items()):\n    if name in got.attrib:\n     continue\n    attrs.append('-%s=\"%s\"'%(name,self.format_text(value,False )))\n  if attrs:\n   tag='<%s %s>'%(tag,' '.join(attrs))\n  else :\n   tag='<%s>'%tag\n  return tag\n  \n def collect_diff_end_tag(self,want,got):\n  if want.tag !=got.tag:\n   tag='%s (got: %s)'%(want.tag,got.tag)\n  else :\n   tag=got.tag\n  return '</%s>'%tag\n  \n def collect_diff_text(self,want,got,strip=True ):\n  if self.text_compare(want,got,strip):\n   if not got:\n    return ''\n   return self.format_text(got,strip)\n  text='%s (got: %s)'%(want,got)\n  return self.format_text(text,strip)\n  \nclass LHTMLOutputChecker(LXMLOutputChecker):\n def get_default_parser(self):\n  return html_fromstring\n  \ndef install(html=False ):\n ''\n\n\n\n\n \n if html:\n  doctest.OutputChecker=LHTMLOutputChecker\n else :\n  doctest.OutputChecker=LXMLOutputChecker\n  \ndef temp_install(html=False ,del_module=None ):\n ''\n\n\n\n\n\n \n if html:\n  Checker=LHTMLOutputChecker\n else :\n  Checker=LXMLOutputChecker\n frame=_find_doctest_frame()\n dt_self=frame.f_locals['self']\n checker=Checker()\n old_checker=dt_self._checker\n dt_self._checker=checker\n \n \n \n \n \n \n \n \n \n if _IS_PYTHON_3:\n  check_func=frame.f_locals['check'].__func__\n  checker_check_func=checker.check_output.__func__\n else :\n  check_func=frame.f_locals['check'].im_func\n  checker_check_func=checker.check_output.im_func\n  \n  \n doctest.etree=etree\n _RestoreChecker(dt_self,old_checker,checker,\n check_func,checker_check_func,\n del_module)\n \nclass _RestoreChecker(object):\n def __init__(self,dt_self,old_checker,new_checker,check_func,clone_func,\n del_module):\n  self.dt_self=dt_self\n  self.checker=old_checker\n  self.checker._temp_call_super_check_output=self.call_super\n  self.checker._temp_override_self=new_checker\n  self.check_func=check_func\n  self.clone_func=clone_func\n  self.del_module=del_module\n  self.install_clone()\n  self.install_dt_self()\n def install_clone(self):\n  if _IS_PYTHON_3:\n   self.func_code=self.check_func.__code__\n   self.func_globals=self.check_func.__globals__\n   self.check_func.__code__=self.clone_func.__code__\n  else :\n   self.func_code=self.check_func.func_code\n   self.func_globals=self.check_func.func_globals\n   self.check_func.func_code=self.clone_func.func_code\n def uninstall_clone(self):\n  if _IS_PYTHON_3:\n   self.check_func.__code__=self.func_code\n  else :\n   self.check_func.func_code=self.func_code\n def install_dt_self(self):\n  self.prev_func=self.dt_self._DocTestRunner__record_outcome\n  self.dt_self._DocTestRunner__record_outcome=self\n def uninstall_dt_self(self):\n  self.dt_self._DocTestRunner__record_outcome=self.prev_func\n def uninstall_module(self):\n  if self.del_module:\n   import sys\n   del sys.modules[self.del_module]\n   if '.'in self.del_module:\n    package,module=self.del_module.rsplit('.',1)\n    package_mod=sys.modules[package]\n    delattr(package_mod,module)\n def __call__(self,*args,**kw):\n  self.uninstall_clone()\n  self.uninstall_dt_self()\n  del self.checker._temp_override_self\n  del self.checker._temp_call_super_check_output\n  result=self.prev_func(*args,**kw)\n  self.uninstall_module()\n  return result\n def call_super(self,*args,**kw):\n  self.uninstall_clone()\n  try :\n   return self.check_func(*args,**kw)\n  finally :\n   self.install_clone()\n   \ndef _find_doctest_frame():\n import sys\n frame=sys._getframe(1)\n while frame:\n  l=frame.f_locals\n  if 'BOOM'in l:\n  \n   return frame\n  frame=frame.f_back\n raise LookupError(\n \"Could not find doctest (only use this function *inside* a doctest)\")\n \n__test__={\n'basic':'''\n    >>> temp_install()\n    >>> print \"\"\"<xml a=\"1\" b=\"2\">stuff</xml>\"\"\"\n    <xml b=\"2\" a=\"1\">...</xml>\n    >>> print \"\"\"<xml xmlns=\"http://example.com\"><tag   attr=\"bar\"   /></xml>\"\"\"\n    <xml xmlns=\"...\">\n      <tag attr=\"...\" />\n    </xml>\n    >>> print \"\"\"<xml>blahblahblah<foo /></xml>\"\"\" # doctest: +NOPARSE_MARKUP, +ELLIPSIS\n    <xml>...foo /></xml>\n    '''}\n\nif __name__ =='__main__':\n import doctest\n doctest.testmod()\n \n \n", ["cgi", "doctest", "html", "lxml", "re", "sys"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.ElementInclude": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\"\nLimited XInclude support for the ElementTree package.\n\nWhile lxml.etree has full support for XInclude (see\n`etree.ElementTree.xinclude()`), this module provides a simpler, pure\nPython, ElementTree compatible implementation that supports a simple\nform of custom URL resolvers.\n\"\"\"\n\nfrom lxml import etree\ntry :\n from urlparse import urljoin\n from urllib2 import urlopen\nexcept ImportError:\n\n from urllib.parse import urljoin\n from urllib.request import urlopen\n \nXINCLUDE=\"{http://www.w3.org/2001/XInclude}\"\n\nXINCLUDE_INCLUDE=XINCLUDE+\"include\"\nXINCLUDE_FALLBACK=XINCLUDE+\"fallback\"\nXINCLUDE_ITER_TAG=XINCLUDE+\"*\"\n\n\nDEFAULT_MAX_INCLUSION_DEPTH=6\n\n\n\n\n\nclass FatalIncludeError(etree.LxmlSyntaxError):\n pass\n \n \nclass LimitedRecursiveIncludeError(FatalIncludeError):\n pass\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ndef default_loader(href,parse,encoding=None ):\n file=open(href,'rb')\n if parse ==\"xml\":\n  data=etree.parse(file).getroot()\n else :\n  data=file.read()\n  if not encoding:\n   encoding='utf-8'\n  data=data.decode(encoding)\n file.close()\n return data\n \n \n \n \n \n \ndef _lxml_default_loader(href,parse,encoding=None ,parser=None ):\n if parse ==\"xml\":\n  data=etree.parse(href,parser).getroot()\n else :\n  if \"://\"in href:\n   f=urlopen(href)\n  else :\n   f=open(href,'rb')\n  data=f.read()\n  f.close()\n  if not encoding:\n   encoding='utf-8'\n  data=data.decode(encoding)\n return data\n \n \n \n \n \ndef _wrap_et_loader(loader):\n def load(href,parse,encoding=None ,parser=None ):\n  return loader(href,parse,encoding)\n return load\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ndef include(elem,loader=None ,base_url=None ,\nmax_depth=DEFAULT_MAX_INCLUSION_DEPTH):\n if max_depth is None :\n  max_depth=-1\n elif max_depth <0:\n  raise ValueError(\"expected non-negative depth or None for 'max_depth', got %r\"%max_depth)\n  \n if base_url is None :\n  if hasattr(elem,'getroot'):\n   tree=elem\n   elem=elem.getroot()\n  else :\n   tree=elem.getroottree()\n  if hasattr(tree,'docinfo'):\n   base_url=tree.docinfo.URL\n elif hasattr(elem,'getroot'):\n  elem=elem.getroot()\n _include(elem,loader,base_url,max_depth)\n \n \ndef _include(elem,loader=None ,base_url=None ,\nmax_depth=DEFAULT_MAX_INCLUSION_DEPTH,_parent_hrefs=None ):\n if loader is not None :\n  load_include=_wrap_et_loader(loader)\n else :\n  load_include=_lxml_default_loader\n  \n if _parent_hrefs is None :\n  _parent_hrefs=set()\n  \n parser=elem.getroottree().parser\n \n include_elements=list(\n elem.iter(XINCLUDE_ITER_TAG))\n \n for e in include_elements:\n  if e.tag ==XINCLUDE_INCLUDE:\n  \n   href=urljoin(base_url,e.get(\"href\"))\n   parse=e.get(\"parse\",\"xml\")\n   parent=e.getparent()\n   if parse ==\"xml\":\n    if href in _parent_hrefs:\n     raise FatalIncludeError(\n     \"recursive include of %r detected\"%href\n     )\n    if max_depth ==0:\n     raise LimitedRecursiveIncludeError(\n     \"maximum xinclude depth reached when including file %s\"%href)\n    node=load_include(href,parse,parser=parser)\n    if node is None :\n     raise FatalIncludeError(\n     \"cannot load %r as %r\"%(href,parse)\n     )\n    node=_include(node,loader,href,max_depth -1,{href}|_parent_hrefs)\n    if e.tail:\n     node.tail=(node.tail or \"\")+e.tail\n    if parent is None :\n     return node\n    parent.replace(e,node)\n   elif parse ==\"text\":\n    text=load_include(href,parse,encoding=e.get(\"encoding\"))\n    if text is None :\n     raise FatalIncludeError(\n     \"cannot load %r as %r\"%(href,parse)\n     )\n    predecessor=e.getprevious()\n    if predecessor is not None :\n     predecessor.tail=(predecessor.tail or \"\")+text\n    elif parent is None :\n     return text\n    else :\n     parent.text=(parent.text or \"\")+text+(e.tail or \"\")\n    parent.remove(e)\n   else :\n    raise FatalIncludeError(\n    \"unknown parse type in xi:include tag (%r)\"%parse\n    )\n  elif e.tag ==XINCLUDE_FALLBACK:\n   parent=e.getparent()\n   if parent is not None and parent.tag !=XINCLUDE_INCLUDE:\n    raise FatalIncludeError(\n    \"xi:fallback tag must be child of xi:include (%r)\"%e.tag\n    )\n  else :\n   raise FatalIncludeError(\n   \"Invalid element found in XInclude namespace (%r)\"%e.tag\n   )\n return elem\n", ["lxml", "urllib.parse", "urllib.request", "urllib2", "urlparse"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.pyclasslookup": [".py", "\n\nfrom lxml.etree import PythonElementClassLookup\n", ["lxml.etree"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.sax": [".py", "\n\n\"\"\"\nSAX-based adapter to copy trees from/to the Python standard library.\n\nUse the `ElementTreeContentHandler` class to build an ElementTree from\nSAX events.\n\nUse the `ElementTreeProducer` class or the `saxify()` function to fire\nthe SAX events of an ElementTree against a SAX ContentHandler.\n\nSee https://lxml.de/sax.html\n\"\"\"\n\nfrom __future__ import absolute_import\n\nfrom xml.sax.handler import ContentHandler\nfrom lxml import etree\nfrom lxml.etree import ElementTree,SubElement\nfrom lxml.etree import Comment,ProcessingInstruction\n\n\nclass SaxError(etree.LxmlError):\n ''\n \n \n \ndef _getNsTag(tag):\n if tag[0]=='{':\n  return tuple(tag[1:].split('}',1))\n else :\n  return None ,tag\n  \n  \nclass ElementTreeContentHandler(ContentHandler):\n ''\n \n def __init__(self,makeelement=None ):\n  ContentHandler.__init__(self)\n  self._root=None\n  self._root_siblings=[]\n  self._element_stack=[]\n  self._default_ns=None\n  self._ns_mapping={None :[None ]}\n  self._new_mappings={}\n  if makeelement is None :\n   makeelement=etree.Element\n  self._makeelement=makeelement\n  \n def _get_etree(self):\n  ''\n  return ElementTree(self._root)\n  \n etree=property(_get_etree,doc=_get_etree.__doc__)\n \n def setDocumentLocator(self,locator):\n  pass\n  \n def startDocument(self):\n  pass\n  \n def endDocument(self):\n  pass\n  \n def startPrefixMapping(self,prefix,uri):\n  self._new_mappings[prefix]=uri\n  try :\n   self._ns_mapping[prefix].append(uri)\n  except KeyError:\n   self._ns_mapping[prefix]=[uri]\n  if prefix is None :\n   self._default_ns=uri\n   \n def endPrefixMapping(self,prefix):\n  ns_uri_list=self._ns_mapping[prefix]\n  ns_uri_list.pop()\n  if prefix is None :\n   self._default_ns=ns_uri_list[-1]\n   \n def _buildTag(self,ns_name_tuple):\n  ns_uri,local_name=ns_name_tuple\n  if ns_uri:\n   el_tag=\"{%s}%s\"%ns_name_tuple\n  elif self._default_ns:\n   el_tag=\"{%s}%s\"%(self._default_ns,local_name)\n  else :\n   el_tag=local_name\n  return el_tag\n  \n def startElementNS(self,ns_name,qname,attributes=None ):\n  el_name=self._buildTag(ns_name)\n  if attributes:\n   attrs={}\n   try :\n    iter_attributes=attributes.iteritems()\n   except AttributeError:\n    iter_attributes=attributes.items()\n    \n   for name_tuple,value in iter_attributes:\n    if name_tuple[0]:\n     attr_name=\"{%s}%s\"%name_tuple\n    else :\n     attr_name=name_tuple[1]\n    attrs[attr_name]=value\n  else :\n   attrs=None\n   \n  element_stack=self._element_stack\n  if self._root is None :\n   element=self._root=\\\n   self._makeelement(el_name,attrs,self._new_mappings)\n   if self._root_siblings and hasattr(element,'addprevious'):\n    for sibling in self._root_siblings:\n     element.addprevious(sibling)\n   del self._root_siblings[:]\n  else :\n   element=SubElement(element_stack[-1],el_name,\n   attrs,self._new_mappings)\n  element_stack.append(element)\n  \n  self._new_mappings.clear()\n  \n def processingInstruction(self,target,data):\n  pi=ProcessingInstruction(target,data)\n  if self._root is None :\n   self._root_siblings.append(pi)\n  else :\n   self._element_stack[-1].append(pi)\n   \n def endElementNS(self,ns_name,qname):\n  element=self._element_stack.pop()\n  el_tag=self._buildTag(ns_name)\n  if el_tag !=element.tag:\n   raise SaxError(\"Unexpected element closed: \"+el_tag)\n   \n def startElement(self,name,attributes=None ):\n  if attributes:\n   attributes=dict(\n   [((None ,k),v)for k,v in attributes.items()]\n   )\n  self.startElementNS((None ,name),name,attributes)\n  \n def endElement(self,name):\n  self.endElementNS((None ,name),name)\n  \n def characters(self,data):\n  last_element=self._element_stack[-1]\n  try :\n  \n   last_element=last_element[-1]\n   last_element.tail=(last_element.tail or '')+data\n  except IndexError:\n  \n   last_element.text=(last_element.text or '')+data\n   \n ignorableWhitespace=characters\n \n \nclass ElementTreeProducer(object):\n ''\n \n def __init__(self,element_or_tree,content_handler):\n  try :\n   element=element_or_tree.getroot()\n  except AttributeError:\n   element=element_or_tree\n  self._element=element\n  self._content_handler=content_handler\n  from xml.sax.xmlreader import AttributesNSImpl as attr_class\n  self._attr_class=attr_class\n  self._empty_attributes=attr_class({},{})\n  \n def saxify(self):\n  self._content_handler.startDocument()\n  \n  element=self._element\n  if hasattr(element,'getprevious'):\n   siblings=[]\n   sibling=element.getprevious()\n   while getattr(sibling,'tag',None )is ProcessingInstruction:\n    siblings.append(sibling)\n    sibling=sibling.getprevious()\n   for sibling in siblings[::-1]:\n    self._recursive_saxify(sibling,{})\n    \n  self._recursive_saxify(element,{})\n  \n  if hasattr(element,'getnext'):\n   sibling=element.getnext()\n   while getattr(sibling,'tag',None )is ProcessingInstruction:\n    self._recursive_saxify(sibling,{})\n    sibling=sibling.getnext()\n    \n  self._content_handler.endDocument()\n  \n def _recursive_saxify(self,element,parent_nsmap):\n  content_handler=self._content_handler\n  tag=element.tag\n  if tag is Comment or tag is ProcessingInstruction:\n   if tag is ProcessingInstruction:\n    content_handler.processingInstruction(\n    element.target,element.text)\n   tail=element.tail\n   if tail:\n    content_handler.characters(tail)\n   return\n   \n  element_nsmap=element.nsmap\n  new_prefixes=[]\n  if element_nsmap !=parent_nsmap:\n  \n   for prefix,ns_uri in element_nsmap.items():\n    if parent_nsmap.get(prefix)!=ns_uri:\n     new_prefixes.append((prefix,ns_uri))\n     \n  attribs=element.items()\n  if attribs:\n   attr_values={}\n   attr_qnames={}\n   for attr_ns_name,value in attribs:\n    attr_ns_tuple=_getNsTag(attr_ns_name)\n    attr_values[attr_ns_tuple]=value\n    attr_qnames[attr_ns_tuple]=self._build_qname(\n    attr_ns_tuple[0],attr_ns_tuple[1],element_nsmap,\n    preferred_prefix=None ,is_attribute=True )\n   sax_attributes=self._attr_class(attr_values,attr_qnames)\n  else :\n   sax_attributes=self._empty_attributes\n   \n  ns_uri,local_name=_getNsTag(tag)\n  qname=self._build_qname(\n  ns_uri,local_name,element_nsmap,element.prefix,is_attribute=False )\n  \n  for prefix,uri in new_prefixes:\n   content_handler.startPrefixMapping(prefix,uri)\n  content_handler.startElementNS(\n  (ns_uri,local_name),qname,sax_attributes)\n  text=element.text\n  if text:\n   content_handler.characters(text)\n  for child in element:\n   self._recursive_saxify(child,element_nsmap)\n  content_handler.endElementNS((ns_uri,local_name),qname)\n  for prefix,uri in new_prefixes:\n   content_handler.endPrefixMapping(prefix)\n  tail=element.tail\n  if tail:\n   content_handler.characters(tail)\n   \n def _build_qname(self,ns_uri,local_name,nsmap,preferred_prefix,is_attribute):\n  if ns_uri is None :\n   return local_name\n   \n  if not is_attribute and nsmap.get(preferred_prefix)==ns_uri:\n   prefix=preferred_prefix\n  else :\n  \n   candidates=[\n   pfx for (pfx,uri)in nsmap.items()\n   if pfx is not None and uri ==ns_uri\n   ]\n   prefix=(\n   candidates[0]if len(candidates)==1\n   else min(candidates)if candidates\n   else None\n   )\n   \n  if prefix is None :\n  \n   return local_name\n  return prefix+':'+local_name\n  \n  \ndef saxify(element_or_tree,content_handler):\n ''\n\n \n return ElementTreeProducer(element_or_tree,content_handler).saxify()\n", ["__future__", "lxml", "lxml.etree", "xml.sax.handler", "xml.sax.xmlreader"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.usedoctest": [".py", "''\n\n\n\n\n\n\n\n\n\nfrom lxml import doctestcompare\n\ndoctestcompare.temp_install(del_module=__name__)\n", ["lxml"]], "bpmn2camel.camel_dsl.Json2Camel.lxml._elementpath": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom __future__ import absolute_import\n\nimport re\n\nxpath_tokenizer_re=re.compile(\n\"(\"\n\"'[^']*'|\\\"[^\\\"]*\\\"|\"\n\"::|\"\n\"//?|\"\nr\"\\.\\.|\"\nr\"\\(\\)|\"\nr\"[/.*:\\[\\]\\(\\)@=])|\"\nr\"((?:\\{[^}]+\\})?[^/\\[\\]\\(\\)@=\\s]+)|\"\nr\"\\s+\"\n)\n\ndef xpath_tokenizer(pattern,namespaces=None ):\n\n default_namespace=(namespaces.get(None )or namespaces.get(''))if namespaces else None\n parsing_attribute=False\n for token in xpath_tokenizer_re.findall(pattern):\n  ttype,tag=token\n  if tag and tag[0]!=\"{\":\n   if \":\"in tag:\n    prefix,uri=tag.split(\":\",1)\n    try :\n     if not namespaces:\n      raise KeyError\n     yield ttype,\"{%s}%s\"%(namespaces[prefix],uri)\n    except KeyError:\n     raise SyntaxError(\"prefix %r not found in prefix map\"%prefix)\n   elif default_namespace and not parsing_attribute:\n    yield ttype,\"{%s}%s\"%(default_namespace,tag)\n   else :\n    yield token\n   parsing_attribute=False\n  else :\n   yield token\n   parsing_attribute=ttype =='@'\n   \n   \ndef prepare_child(next,token):\n tag=token[1]\n def select(result):\n  for elem in result:\n   for e in elem.iterchildren(tag):\n    yield e\n return select\n \ndef prepare_star(next,token):\n def select(result):\n  for elem in result:\n   for e in elem.iterchildren('*'):\n    yield e\n return select\n \ndef prepare_self(next,token):\n def select(result):\n  return result\n return select\n \ndef prepare_descendant(next,token):\n token=next()\n if token[0]==\"*\":\n  tag=\"*\"\n elif not token[0]:\n  tag=token[1]\n else :\n  raise SyntaxError(\"invalid descendant\")\n def select(result):\n  for elem in result:\n   for e in elem.iterdescendants(tag):\n    yield e\n return select\n \ndef prepare_parent(next,token):\n def select(result):\n  for elem in result:\n   parent=elem.getparent()\n   if parent is not None :\n    yield parent\n return select\n \ndef prepare_predicate(next,token):\n\n\n\n signature=''\n predicate=[]\n while 1:\n  token=next()\n  if token[0]==\"]\":\n   break\n  if token ==('',''):\n  \n   continue\n  if token[0]and token[0][:1]in \"'\\\"\":\n   token=\"'\",token[0][1:-1]\n  signature +=token[0]or \"-\"\n  predicate.append(token[1])\n  \n  \n if signature ==\"@-\":\n \n  key=predicate[1]\n  def select(result):\n   for elem in result:\n    if elem.get(key)is not None :\n     yield elem\n  return select\n if signature ==\"@-='\":\n \n  key=predicate[1]\n  value=predicate[-1]\n  def select(result):\n   for elem in result:\n    if elem.get(key)==value:\n     yield elem\n  return select\n if signature ==\"-\"and not re.match(r\"-?\\d+$\",predicate[0]):\n \n  tag=predicate[0]\n  def select(result):\n   for elem in result:\n    for _ in elem.iterchildren(tag):\n     yield elem\n     break\n  return select\n if signature ==\".='\"or (signature ==\"-='\"and not re.match(r\"-?\\d+$\",predicate[0])):\n \n  tag=predicate[0]\n  value=predicate[-1]\n  if tag:\n   def select(result):\n    for elem in result:\n     for e in elem.iterchildren(tag):\n      if \"\".join(e.itertext())==value:\n       yield elem\n       break\n  else :\n   def select(result):\n    for elem in result:\n     if \"\".join(elem.itertext())==value:\n      yield elem\n  return select\n if signature ==\"-\"or signature ==\"-()\"or signature ==\"-()-\":\n \n  if signature ==\"-\":\n  \n   index=int(predicate[0])-1\n   if index <0:\n    if index ==-1:\n     raise SyntaxError(\n     \"indices in path predicates are 1-based, not 0-based\")\n    else :\n     raise SyntaxError(\"path index >= 1 expected\")\n  else :\n   if predicate[0]!=\"last\":\n    raise SyntaxError(\"unsupported function\")\n   if signature ==\"-()-\":\n    try :\n     index=int(predicate[2])-1\n    except ValueError:\n     raise SyntaxError(\"unsupported expression\")\n   else :\n    index=-1\n  def select(result):\n   for elem in result:\n    parent=elem.getparent()\n    if parent is None :\n     continue\n    try :\n    \n     elems=list(parent.iterchildren(elem.tag))\n     if elems[index]is elem:\n      yield elem\n    except IndexError:\n     pass\n  return select\n raise SyntaxError(\"invalid predicate\")\n \nops={\n\"\":prepare_child,\n\"*\":prepare_star,\n\".\":prepare_self,\n\"..\":prepare_parent,\n\"//\":prepare_descendant,\n\"[\":prepare_predicate,\n}\n\n\n\n\n_cache={}\n\n\ndef _build_path_iterator(path,namespaces):\n ''\n if path[-1:]==\"/\":\n  path +=\"*\"\n  \n cache_key=(path,)\n if namespaces:\n \n \n \n  if None in namespaces:\n   if ''in namespaces and namespaces[None ]!=namespaces['']:\n    raise ValueError(\"Ambiguous default namespace provided: %r versus %r\"%(\n    namespaces[None ],namespaces['']))\n   cache_key +=(namespaces[None ],)+tuple(sorted(\n   item for item in namespaces.items()if item[0]is not None ))\n  else :\n   cache_key +=tuple(sorted(namespaces.items()))\n   \n try :\n  return _cache[cache_key]\n except KeyError:\n  pass\n if len(_cache)>100:\n  _cache.clear()\n  \n if path[:1]==\"/\":\n  raise SyntaxError(\"cannot use absolute path on element\")\n stream=iter(xpath_tokenizer(path,namespaces))\n try :\n  _next=stream.next\n except AttributeError:\n \n  _next=stream.__next__\n try :\n  token=_next()\n except StopIteration:\n  raise SyntaxError(\"empty path expression\")\n selector=[]\n while 1:\n  try :\n   selector.append(ops[token[0]](_next,token))\n  except StopIteration:\n   raise SyntaxError(\"invalid path\")\n  try :\n   token=_next()\n   if token[0]==\"/\":\n    token=_next()\n  except StopIteration:\n   break\n _cache[cache_key]=selector\n return selector\n \n \n \n \n \ndef iterfind(elem,path,namespaces=None ):\n selector=_build_path_iterator(path,namespaces)\n result=iter((elem,))\n for select in selector:\n  result=select(result)\n return result\n \n \n \n \n \ndef find(elem,path,namespaces=None ):\n it=iterfind(elem,path,namespaces)\n try :\n  return next(it)\n except StopIteration:\n  return None\n  \n  \n  \n  \n  \ndef findall(elem,path,namespaces=None ):\n return list(iterfind(elem,path,namespaces))\n \n \n \n \n \ndef findtext(elem,path,default=None ,namespaces=None ):\n el=find(elem,path,namespaces)\n if el is None :\n  return default\n else :\n  return el.text or ''\n", ["__future__", "re"]], "bpmn2camel.camel_dsl.Json2Camel.lxml": [".py", "\n\n__version__=\"4.6.4\"\n\n\ndef get_include():\n ''\n\n\n\n \n import os\n lxml_path=__path__[0]\n include_path=os.path.join(lxml_path,'includes')\n includes=[include_path,lxml_path]\n \n for name in os.listdir(include_path):\n  path=os.path.join(include_path,name)\n  if os.path.isdir(path):\n   includes.append(path)\n   \n return includes\n \n", ["os"], 1], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.builder": [".py", "\n\n\n\n\n\"\"\"\nA set of HTML generator tags for building HTML documents.\n\nUsage::\n\n    >>> from lxml.html.builder import *\n    >>> html = HTML(\n    ...            HEAD( TITLE(\"Hello World\") ),\n    ...            BODY( CLASS(\"main\"),\n    ...                  H1(\"Hello World !\")\n    ...            )\n    ...        )\n\n    >>> import lxml.etree\n    >>> print lxml.etree.tostring(html, pretty_print=True)\n    <html>\n      <head>\n        <title>Hello World</title>\n      </head>\n      <body class=\"main\">\n        <h1>Hello World !</h1>\n      </body>\n    </html>\n\n\"\"\"\n\nfrom lxml.builder import ElementMaker\nfrom lxml.html import html_parser\n\nE=ElementMaker(makeelement=html_parser.makeelement)\n\n\nA=E.a\nABBR=E.abbr\nACRONYM=E.acronym\nADDRESS=E.address\nAPPLET=E.applet\nAREA=E.area\nB=E.b\nBASE=E.base\nBASEFONT=E.basefont\nBDO=E.bdo\nBIG=E.big\nBLOCKQUOTE=E.blockquote\nBODY=E.body\nBR=E.br\nBUTTON=E.button\nCAPTION=E.caption\nCENTER=E.center\nCITE=E.cite\nCODE=E.code\nCOL=E.col\nCOLGROUP=E.colgroup\nDD=E.dd\nDEL=getattr(E,'del')\nDFN=E.dfn\nDIR=E.dir\nDIV=E.div\nDL=E.dl\nDT=E.dt\nEM=E.em\nFIELDSET=E.fieldset\nFONT=E.font\nFORM=E.form\nFRAME=E.frame\nFRAMESET=E.frameset\nH1=E.h1\nH2=E.h2\nH3=E.h3\nH4=E.h4\nH5=E.h5\nH6=E.h6\nHEAD=E.head\nHR=E.hr\nHTML=E.html\nI=E.i\nIFRAME=E.iframe\nIMG=E.img\nINPUT=E.input\nINS=E.ins\nISINDEX=E.isindex\nKBD=E.kbd\nLABEL=E.label\nLEGEND=E.legend\nLI=E.li\nLINK=E.link\nMAP=E.map\nMENU=E.menu\nMETA=E.meta\nNOFRAMES=E.noframes\nNOSCRIPT=E.noscript\nOBJECT=E.object\nOL=E.ol\nOPTGROUP=E.optgroup\nOPTION=E.option\nP=E.p\nPARAM=E.param\nPRE=E.pre\nQ=E.q\nS=E.s\nSAMP=E.samp\nSCRIPT=E.script\nSELECT=E.select\nSMALL=E.small\nSPAN=E.span\nSTRIKE=E.strike\nSTRONG=E.strong\nSTYLE=E.style\nSUB=E.sub\nSUP=E.sup\nTABLE=E.table\nTBODY=E.tbody\nTD=E.td\nTEXTAREA=E.textarea\nTFOOT=E.tfoot\nTH=E.th\nTHEAD=E.thead\nTITLE=E.title\nTR=E.tr\nTT=E.tt\nU=E.u\nUL=E.ul\nVAR=E.var\n\n\nATTR=dict\ndef CLASS(v):return {'class':v}\ndef FOR(v):return {'for':v}\n", ["lxml.builder", "lxml.html"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.clean": [".py", "\n\n\"\"\"A cleanup tool for HTML.\n\nRemoves unwanted tags and content.  See the `Cleaner` class for\ndetails.\n\"\"\"\n\nfrom __future__ import absolute_import\n\nimport copy\nimport re\nimport sys\ntry :\n from urlparse import urlsplit\n from urllib import unquote_plus\nexcept ImportError:\n\n from urllib.parse import urlsplit,unquote_plus\nfrom lxml import etree\nfrom lxml.html import defs\nfrom lxml.html import fromstring,XHTML_NAMESPACE\nfrom lxml.html import xhtml_to_html,_transform_result\n\ntry :\n unichr\nexcept NameError:\n\n unichr=chr\ntry :\n unicode\nexcept NameError:\n\n unicode=str\ntry :\n basestring\nexcept NameError:\n basestring=(str,bytes)\n \n \n__all__=['clean_html','clean','Cleaner','autolink','autolink_html',\n'word_break','word_break_html']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n_replace_css_javascript=re.compile(\nr'expression\\s*\\(.*?\\)',re.S |re.I).sub\n\n\n_replace_css_import=re.compile(\nr'@\\s*import',re.I).sub\n\n_looks_like_tag_content=re.compile(\nr'</?[a-zA-Z]+|\\son[a-zA-Z]+\\s*=',\n*((re.ASCII,)if sys.version_info[0]>=3 else ())).search\n\n\n\n_is_image_dataurl=re.compile(\nr'^data:image/.+;base64',re.I).search\n_is_possibly_malicious_scheme=re.compile(\nr'(?:javascript|jscript|livescript|vbscript|data|about|mocha):',\nre.I).search\ndef _is_javascript_scheme(s):\n if _is_image_dataurl(s):\n  return None\n return _is_possibly_malicious_scheme(s)\n \n_substitute_whitespace=re.compile(r'[\\s\\x00-\\x08\\x0B\\x0C\\x0E-\\x19]+').sub\n\n\n\n_conditional_comment_re=re.compile(\nr'\\[if[\\s\\n\\r]+.*?][\\s\\n\\r]*>',re.I |re.S)\n\n_find_styled_elements=etree.XPath(\n\"descendant-or-self::*[@style]\")\n\n_find_external_links=etree.XPath(\n(\"descendant-or-self::a  [normalize-space(@href) and substring(normalize-space(@href),1,1) != '#'] |\"\n\"descendant-or-self::x:a[normalize-space(@href) and substring(normalize-space(@href),1,1) != '#']\"),\nnamespaces={'x':XHTML_NAMESPACE})\n\n\nclass Cleaner(object):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n scripts=True\n javascript=True\n comments=True\n style=False\n inline_style=None\n links=True\n meta=True\n page_structure=True\n processing_instructions=True\n embedded=True\n frames=True\n forms=True\n annoying_tags=True\n remove_tags=None\n allow_tags=None\n kill_tags=None\n remove_unknown_tags=True\n safe_attrs_only=True\n safe_attrs=defs.safe_attrs\n add_nofollow=False\n host_whitelist=()\n whitelist_tags={'iframe','embed'}\n \n def __init__(self,**kw):\n  not_an_attribute=object()\n  for name,value in kw.items():\n   default=getattr(self,name,not_an_attribute)\n   if (default is not None and default is not True and default is not False\n   and not isinstance(default,(frozenset,set,tuple,list))):\n    raise TypeError(\n    \"Unknown parameter: %s=%r\"%(name,value))\n   setattr(self,name,value)\n  if self.inline_style is None and 'inline_style'not in kw:\n   self.inline_style=self.style\n   \n  if kw.get(\"allow_tags\"):\n   if kw.get(\"remove_unknown_tags\"):\n    raise ValueError(\"It does not make sense to pass in both \"\n    \"allow_tags and remove_unknown_tags\")\n   self.remove_unknown_tags=False\n   \n   \n   \n _tag_link_attrs=dict(\n script='src',\n link='href',\n \n \n applet=['code','object'],\n iframe='src',\n embed='src',\n layer='src',\n \n \n \n \n \n \n \n \n a='href',\n )\n \n def __call__(self,doc):\n  ''\n\n  \n  try :\n   getroot=doc.getroot\n  except AttributeError:\n   pass\n  else :\n   doc=getroot()\n   \n  xhtml_to_html(doc)\n  \n  \n  for el in doc.iter('image'):\n   el.tag='img'\n  if not self.comments:\n  \n  \n   self.kill_conditional_comments(doc)\n   \n  kill_tags=set(self.kill_tags or ())\n  remove_tags=set(self.remove_tags or ())\n  allow_tags=set(self.allow_tags or ())\n  \n  if self.scripts:\n   kill_tags.add('script')\n  if self.safe_attrs_only:\n   safe_attrs=set(self.safe_attrs)\n   for el in doc.iter(etree.Element):\n    attrib=el.attrib\n    for aname in attrib.keys():\n     if aname not in safe_attrs:\n      del attrib[aname]\n  if self.javascript:\n   if not (self.safe_attrs_only and\n   self.safe_attrs ==defs.safe_attrs):\n   \n    for el in doc.iter(etree.Element):\n     attrib=el.attrib\n     for aname in attrib.keys():\n      if aname.startswith('on'):\n       del attrib[aname]\n   doc.rewrite_links(self._remove_javascript_link,\n   resolve_base_href=False )\n   \n   \n   if not self.inline_style:\n    for el in _find_styled_elements(doc):\n     old=el.get('style')\n     new=_replace_css_javascript('',old)\n     new=_replace_css_import('',new)\n     if self._has_sneaky_javascript(new):\n     \n      del el.attrib['style']\n     elif new !=old:\n      el.set('style',new)\n   if not self.style:\n    for el in list(doc.iter('style')):\n     if el.get('type','').lower().strip()=='text/javascript':\n      el.drop_tree()\n      continue\n     old=el.text or ''\n     new=_replace_css_javascript('',old)\n     \n     new=_replace_css_import('',new)\n     if self._has_sneaky_javascript(new):\n     \n      el.text='/* deleted */'\n     elif new !=old:\n      el.text=new\n  if self.comments:\n   kill_tags.add(etree.Comment)\n  if self.processing_instructions:\n   kill_tags.add(etree.ProcessingInstruction)\n  if self.style:\n   kill_tags.add('style')\n  if self.inline_style:\n   etree.strip_attributes(doc,'style')\n  if self.links:\n   kill_tags.add('link')\n  elif self.style or self.javascript:\n  \n  \n   for el in list(doc.iter('link')):\n    if 'stylesheet'in el.get('rel','').lower():\n    \n     if not self.allow_element(el):\n      el.drop_tree()\n  if self.meta:\n   kill_tags.add('meta')\n  if self.page_structure:\n   remove_tags.update(('head','html','title'))\n  if self.embedded:\n  \n  \n  \n   for el in list(doc.iter('param')):\n    parent=el.getparent()\n    while parent is not None and parent.tag not in ('applet','object'):\n     parent=parent.getparent()\n    if parent is None :\n     el.drop_tree()\n   kill_tags.update(('applet',))\n   \n   remove_tags.update(('iframe','embed','layer','object','param'))\n  if self.frames:\n  \n  \n  \n   kill_tags.update(defs.frame_tags)\n  if self.forms:\n   remove_tags.add('form')\n   kill_tags.update(('button','input','select','textarea'))\n  if self.annoying_tags:\n   remove_tags.update(('blink','marquee'))\n   \n  _remove=[]\n  _kill=[]\n  for el in doc.iter():\n   if el.tag in kill_tags:\n    if self.allow_element(el):\n     continue\n    _kill.append(el)\n   elif el.tag in remove_tags:\n    if self.allow_element(el):\n     continue\n    _remove.append(el)\n    \n  if _remove and _remove[0]==doc:\n  \n  \n   el=_remove.pop(0)\n   el.tag='div'\n   el.attrib.clear()\n  elif _kill and _kill[0]==doc:\n  \n  \n   el=_kill.pop(0)\n   if el.tag !='html':\n    el.tag='div'\n   el.clear()\n   \n  _kill.reverse()\n  for el in _kill:\n   el.drop_tree()\n  for el in _remove:\n   el.drop_tag()\n   \n  if self.remove_unknown_tags:\n   if allow_tags:\n    raise ValueError(\n    \"It does not make sense to pass in both allow_tags and remove_unknown_tags\")\n   allow_tags=set(defs.tags)\n  if allow_tags:\n  \n   if not self.comments:\n    allow_tags.add(etree.Comment)\n   if not self.processing_instructions:\n    allow_tags.add(etree.ProcessingInstruction)\n    \n   bad=[]\n   for el in doc.iter():\n    if el.tag not in allow_tags:\n     bad.append(el)\n   if bad:\n    if bad[0]is doc:\n     el=bad.pop(0)\n     el.tag='div'\n     el.attrib.clear()\n    for el in bad:\n     el.drop_tag()\n  if self.add_nofollow:\n   for el in _find_external_links(doc):\n    if not self.allow_follow(el):\n     rel=el.get('rel')\n     if rel:\n      if ('nofollow'in rel\n      and ' nofollow 'in (' %s '%rel)):\n       continue\n      rel='%s nofollow'%rel\n     else :\n      rel='nofollow'\n     el.set('rel',rel)\n     \n def allow_follow(self,anchor):\n  ''\n\n  \n  return False\n  \n def allow_element(self,el):\n  ''\n\n\n\n\n  \n  if el.tag not in self._tag_link_attrs:\n   return False\n  attr=self._tag_link_attrs[el.tag]\n  if isinstance(attr,(list,tuple)):\n   for one_attr in attr:\n    url=el.get(one_attr)\n    if not url:\n     return False\n    if not self.allow_embedded_url(el,url):\n     return False\n   return True\n  else :\n   url=el.get(attr)\n   if not url:\n    return False\n   return self.allow_embedded_url(el,url)\n   \n def allow_embedded_url(self,el,url):\n  ''\n\n\n\n\n\n\n  \n  if self.whitelist_tags is not None and el.tag not in self.whitelist_tags:\n   return False\n  scheme,netloc,path,query,fragment=urlsplit(url)\n  netloc=netloc.lower().split(':',1)[0]\n  if scheme not in ('http','https'):\n   return False\n  if netloc in self.host_whitelist:\n   return True\n  return False\n  \n def kill_conditional_comments(self,doc):\n  ''\n\n\n\n  \n  has_conditional_comment=_conditional_comment_re.search\n  self._kill_elements(\n  doc,lambda el:has_conditional_comment(el.text),\n  etree.Comment)\n  \n def _kill_elements(self,doc,condition,iterate=None ):\n  bad=[]\n  for el in doc.iter(iterate):\n   if condition(el):\n    bad.append(el)\n  for el in bad:\n   el.drop_tree()\n   \n def _remove_javascript_link(self,link):\n \n  new=_substitute_whitespace('',unquote_plus(link))\n  if _is_javascript_scheme(new):\n  \n   return ''\n  return link\n  \n _substitute_comments=re.compile(r'/\\*.*?\\*/',re.S).sub\n \n def _has_sneaky_javascript(self,style):\n  ''\n\n\n\n\n\n\n\n\n  \n  style=self._substitute_comments('',style)\n  style=style.replace('\\\\','')\n  style=_substitute_whitespace('',style)\n  style=style.lower()\n  if 'javascript:'in style:\n   return True\n  if 'expression('in style:\n   return True\n  if '</noscript'in style:\n  \n   return True\n  if _looks_like_tag_content(style):\n  \n   return True\n  return False\n  \n def clean_html(self,html):\n  result_type=type(html)\n  if isinstance(html,basestring):\n   doc=fromstring(html)\n  else :\n   doc=copy.deepcopy(html)\n  self(doc)\n  return _transform_result(result_type,doc)\n  \nclean=Cleaner()\nclean_html=clean.clean_html\n\n\n\n\n\n_link_regexes=[\nre.compile(r'(?P<body>https?://(?P<host>[a-z0-9._-]+)(?:/[/\\-_.,a-z0-9%&?;=~]*)?(?:\\([/\\-_.,a-z0-9%&?;=~]*\\))?)',re.I),\n\nre.compile(r'mailto:(?P<body>[a-z0-9._-]+@(?P<host>[a-z0-9_.-]+[a-z]))',re.I),\n]\n\n_avoid_elements=['textarea','pre','code','head','select','a']\n\n_avoid_hosts=[\nre.compile(r'^localhost',re.I),\nre.compile(r'\\bexample\\.(?:com|org|net)$',re.I),\nre.compile(r'^127\\.0\\.0\\.1$'),\n]\n\n_avoid_classes=['nolink']\n\ndef autolink(el,link_regexes=_link_regexes,\navoid_elements=_avoid_elements,\navoid_hosts=_avoid_hosts,\navoid_classes=_avoid_classes):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n \n if el.tag in avoid_elements:\n  return\n class_name=el.get('class')\n if class_name:\n  class_name=class_name.split()\n  for match_class in avoid_classes:\n   if match_class in class_name:\n    return\n for child in list(el):\n  autolink(child,link_regexes=link_regexes,\n  avoid_elements=avoid_elements,\n  avoid_hosts=avoid_hosts,\n  avoid_classes=avoid_classes)\n  if child.tail:\n   text,tail_children=_link_text(\n   child.tail,link_regexes,avoid_hosts,factory=el.makeelement)\n   if tail_children:\n    child.tail=text\n    index=el.index(child)\n    el[index+1:index+1]=tail_children\n if el.text:\n  text,pre_children=_link_text(\n  el.text,link_regexes,avoid_hosts,factory=el.makeelement)\n  if pre_children:\n   el.text=text\n   el[:0]=pre_children\n   \ndef _link_text(text,link_regexes,avoid_hosts,factory):\n leading_text=''\n links=[]\n last_pos=0\n while 1:\n  best_match,best_pos=None ,None\n  for regex in link_regexes:\n   regex_pos=last_pos\n   while 1:\n    match=regex.search(text,pos=regex_pos)\n    if match is None :\n     break\n    host=match.group('host')\n    for host_regex in avoid_hosts:\n     if host_regex.search(host):\n      regex_pos=match.end()\n      break\n    else :\n     break\n   if match is None :\n    continue\n   if best_pos is None or match.start()<best_pos:\n    best_match=match\n    best_pos=match.start()\n  if best_match is None :\n  \n   if links:\n    assert not links[-1].tail\n    links[-1].tail=text\n   else :\n    assert not leading_text\n    leading_text=text\n   break\n  link=best_match.group(0)\n  end=best_match.end()\n  if link.endswith('.')or link.endswith(','):\n  \n   end -=1\n   link=link[:-1]\n  prev_text=text[:best_match.start()]\n  if links:\n   assert not links[-1].tail\n   links[-1].tail=prev_text\n  else :\n   assert not leading_text\n   leading_text=prev_text\n  anchor=factory('a')\n  anchor.set('href',link)\n  body=best_match.group('body')\n  if not body:\n   body=link\n  if body.endswith('.')or body.endswith(','):\n   body=body[:-1]\n  anchor.text=body\n  links.append(anchor)\n  text=text[end:]\n return leading_text,links\n \ndef autolink_html(html,*args,**kw):\n result_type=type(html)\n if isinstance(html,basestring):\n  doc=fromstring(html)\n else :\n  doc=copy.deepcopy(html)\n autolink(doc,*args,**kw)\n return _transform_result(result_type,doc)\n \nautolink_html.__doc__=autolink.__doc__\n\n\n\n\n\n_avoid_word_break_elements=['pre','textarea','code']\n_avoid_word_break_classes=['nobreak']\n\ndef word_break(el,max_width=40,\navoid_elements=_avoid_word_break_elements,\navoid_classes=_avoid_word_break_classes,\nbreak_character=unichr(0x200b)):\n ''\n\n\n\n\n\n\n\n\n\n\n\n \n \n \n if el.tag in _avoid_word_break_elements:\n  return\n class_name=el.get('class')\n if class_name:\n  dont_break=False\n  class_name=class_name.split()\n  for avoid in avoid_classes:\n   if avoid in class_name:\n    dont_break=True\n    break\n  if dont_break:\n   return\n if el.text:\n  el.text=_break_text(el.text,max_width,break_character)\n for child in el:\n  word_break(child,max_width=max_width,\n  avoid_elements=avoid_elements,\n  avoid_classes=avoid_classes,\n  break_character=break_character)\n  if child.tail:\n   child.tail=_break_text(child.tail,max_width,break_character)\n   \ndef word_break_html(html,*args,**kw):\n result_type=type(html)\n doc=fromstring(html)\n word_break(doc,*args,**kw)\n return _transform_result(result_type,doc)\n \ndef _break_text(text,max_width,break_character):\n words=text.split()\n for word in words:\n  if len(word)>max_width:\n   replacement=_insert_break(word,max_width,break_character)\n   text=text.replace(word,replacement)\n return text\n \n_break_prefer_re=re.compile(r'[^a-z]',re.I)\n\ndef _insert_break(word,width,break_character):\n orig_word=word\n result=''\n while len(word)>width:\n  start=word[:width]\n  breaks=list(_break_prefer_re.finditer(start))\n  if breaks:\n   last_break=breaks[-1]\n   \n   if last_break.end()>width -10:\n   \n   \n    start=word[:last_break.end()]\n  result +=start+break_character\n  word=word[len(start):]\n result +=word\n return result\n \n", ["__future__", "copy", "lxml", "lxml.html", "re", "sys", "urllib", "urllib.parse", "urlparse"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.defs": [".py", "\n\n\n\n\"\"\"\nData taken from https://www.w3.org/TR/html401/index/elements.html\nand https://www.w3.org/community/webed/wiki/HTML/New_HTML5_Elements\nfor html5_tags.\n\"\"\"\n\nempty_tags=frozenset([\n'area','base','basefont','br','col','frame','hr',\n'img','input','isindex','link','meta','param','source','track'])\n\ndeprecated_tags=frozenset([\n'applet','basefont','center','dir','font','isindex',\n'menu','s','strike','u'])\n\n\nlink_attrs=frozenset([\n'action','archive','background','cite','classid',\n'codebase','data','href','longdesc','profile','src',\n'usemap',\n\n'dynsrc','lowsrc',\n\n'formaction'\n])\n\n\n\nevent_attrs=frozenset([\n'onblur','onchange','onclick','ondblclick','onerror',\n'onfocus','onkeydown','onkeypress','onkeyup','onload',\n'onmousedown','onmousemove','onmouseout','onmouseover',\n'onmouseup','onreset','onresize','onselect','onsubmit',\n'onunload',\n])\n\nsafe_attrs=frozenset([\n'abbr','accept','accept-charset','accesskey','action','align',\n'alt','axis','border','cellpadding','cellspacing','char','charoff',\n'charset','checked','cite','class','clear','cols','colspan',\n'color','compact','coords','datetime','dir','disabled','enctype',\n'for','frame','headers','height','href','hreflang','hspace','id',\n'ismap','label','lang','longdesc','maxlength','media','method',\n'multiple','name','nohref','noshade','nowrap','prompt','readonly',\n'rel','rev','rows','rowspan','rules','scope','selected','shape',\n'size','span','src','start','summary','tabindex','target','title',\n'type','usemap','valign','value','vspace','width'])\n\n\ntop_level_tags=frozenset([\n'html','head','body','frameset',\n])\n\nhead_tags=frozenset([\n'base','isindex','link','meta','script','style','title',\n])\n\ngeneral_block_tags=frozenset([\n'address',\n'blockquote',\n'center',\n'del',\n'div',\n'h1',\n'h2',\n'h3',\n'h4',\n'h5',\n'h6',\n'hr',\n'ins',\n'isindex',\n'noscript',\n'p',\n'pre',\n])\n\nlist_tags=frozenset([\n'dir','dl','dt','dd','li','menu','ol','ul',\n])\n\ntable_tags=frozenset([\n'table','caption','colgroup','col',\n'thead','tfoot','tbody','tr','td','th',\n])\n\n\n\nblock_tags=general_block_tags |list_tags |table_tags |frozenset([\n\n'fieldset','form','legend','optgroup','option',\n])\n\nform_tags=frozenset([\n'form','button','fieldset','legend','input','label',\n'select','optgroup','option','textarea',\n])\n\nspecial_inline_tags=frozenset([\n'a','applet','basefont','bdo','br','embed','font','iframe',\n'img','map','area','object','param','q','script',\n'span','sub','sup',\n])\n\nphrase_tags=frozenset([\n'abbr','acronym','cite','code','del','dfn','em',\n'ins','kbd','samp','strong','var',\n])\n\nfont_style_tags=frozenset([\n'b','big','i','s','small','strike','tt','u',\n])\n\nframe_tags=frozenset([\n'frameset','frame','noframes',\n])\n\nhtml5_tags=frozenset([\n'article','aside','audio','canvas','command','datalist',\n'details','embed','figcaption','figure','footer','header',\n'hgroup','keygen','mark','math','meter','nav','output',\n'progress','rp','rt','ruby','section','source','summary',\n'svg','time','track','video','wbr'\n])\n\n\nnonstandard_tags=frozenset(['blink','marquee'])\n\n\ntags=(top_level_tags |head_tags |general_block_tags |list_tags\n|table_tags |form_tags |special_inline_tags |phrase_tags\n|font_style_tags |nonstandard_tags |html5_tags)\n", []], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.diff": [".py", "\n\nfrom __future__ import absolute_import\n\nimport difflib\nfrom lxml import etree\nfrom lxml.html import fragment_fromstring\nimport re\n\n__all__=['html_annotate','htmldiff']\n\ntry :\n from html import escape as html_escape\nexcept ImportError:\n from cgi import escape as html_escape\ntry :\n _unicode=unicode\nexcept NameError:\n\n _unicode=str\ntry :\n basestring\nexcept NameError:\n\n basestring=str\n \n \n \n \n \ndef default_markup(text,version):\n return '<span title=\"%s\">%s</span>'%(\n html_escape(_unicode(version),1),text)\n \ndef html_annotate(doclist,markup=default_markup):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n \n \n \n \n tokenlist=[tokenize_annotated(doc,version)\n for doc,version in doclist]\n cur_tokens=tokenlist[0]\n for tokens in tokenlist[1:]:\n  html_annotate_merge_annotations(cur_tokens,tokens)\n  cur_tokens=tokens\n  \n  \n  \n cur_tokens=compress_tokens(cur_tokens)\n \n result=markup_serialize_tokens(cur_tokens,markup)\n return ''.join(result).strip()\n \ndef tokenize_annotated(doc,annotation):\n ''\n \n tokens=tokenize(doc,include_hrefs=False )\n for tok in tokens:\n  tok.annotation=annotation\n return tokens\n \ndef html_annotate_merge_annotations(tokens_old,tokens_new):\n ''\n\n \n s=InsensitiveSequenceMatcher(a=tokens_old,b=tokens_new)\n commands=s.get_opcodes()\n \n for command,i1,i2,j1,j2 in commands:\n  if command =='equal':\n   eq_old=tokens_old[i1:i2]\n   eq_new=tokens_new[j1:j2]\n   copy_annotations(eq_old,eq_new)\n   \ndef copy_annotations(src,dest):\n ''\n\n \n assert len(src)==len(dest)\n for src_tok,dest_tok in zip(src,dest):\n  dest_tok.annotation=src_tok.annotation\n  \ndef compress_tokens(tokens):\n ''\n\n\n \n result=[tokens[0]]\n for tok in tokens[1:]:\n  if (not result[-1].post_tags and\n  not tok.pre_tags and\n  result[-1].annotation ==tok.annotation):\n   compress_merge_back(result,tok)\n  else :\n   result.append(tok)\n return result\n \ndef compress_merge_back(tokens,tok):\n ''\n \n last=tokens[-1]\n if type(last)is not token or type(tok)is not token:\n  tokens.append(tok)\n else :\n  text=_unicode(last)\n  if last.trailing_whitespace:\n   text +=last.trailing_whitespace\n  text +=tok\n  merged=token(text,\n  pre_tags=last.pre_tags,\n  post_tags=tok.post_tags,\n  trailing_whitespace=tok.trailing_whitespace)\n  merged.annotation=last.annotation\n  tokens[-1]=merged\n  \ndef markup_serialize_tokens(tokens,markup_func):\n ''\n\n\n \n for token in tokens:\n  for pre in token.pre_tags:\n   yield pre\n  html=token.html()\n  html=markup_func(html,token.annotation)\n  if token.trailing_whitespace:\n   html +=token.trailing_whitespace\n  yield html\n  for post in token.post_tags:\n   yield post\n   \n   \n   \n   \n   \n   \ndef htmldiff(old_html,new_html):\n\n\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n \n old_html_tokens=tokenize(old_html)\n new_html_tokens=tokenize(new_html)\n result=htmldiff_tokens(old_html_tokens,new_html_tokens)\n result=''.join(result).strip()\n return fixup_ins_del_tags(result)\n \ndef htmldiff_tokens(html1_tokens,html2_tokens):\n ''\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n s=InsensitiveSequenceMatcher(a=html1_tokens,b=html2_tokens)\n commands=s.get_opcodes()\n result=[]\n for command,i1,i2,j1,j2 in commands:\n  if command =='equal':\n   result.extend(expand_tokens(html2_tokens[j1:j2],equal=True ))\n   continue\n  if command =='insert'or command =='replace':\n   ins_tokens=expand_tokens(html2_tokens[j1:j2])\n   merge_insert(ins_tokens,result)\n  if command =='delete'or command =='replace':\n   del_tokens=expand_tokens(html1_tokens[i1:i2])\n   merge_delete(del_tokens,result)\n   \n   \n   \n   \n result=cleanup_delete(result)\n \n return result\n \ndef expand_tokens(tokens,equal=False ):\n ''\n\n \n for token in tokens:\n  for pre in token.pre_tags:\n   yield pre\n  if not equal or not token.hide_when_equal:\n   if token.trailing_whitespace:\n    yield token.html()+token.trailing_whitespace\n   else :\n    yield token.html()\n  for post in token.post_tags:\n   yield post\n   \ndef merge_insert(ins_chunks,doc):\n ''\n \n \n \n \n unbalanced_start,balanced,unbalanced_end=split_unbalanced(ins_chunks)\n doc.extend(unbalanced_start)\n if doc and not doc[-1].endswith(' '):\n \n \n  doc[-1]+=' '\n doc.append('<ins>')\n if balanced and balanced[-1].endswith(' '):\n \n  balanced[-1]=balanced[-1][:-1]\n doc.extend(balanced)\n doc.append('</ins> ')\n doc.extend(unbalanced_end)\n \n \n \n \nclass DEL_START:\n pass\nclass DEL_END:\n pass\n \nclass NoDeletes(Exception):\n ''\n \n \ndef merge_delete(del_chunks,doc):\n ''\n\n \n doc.append(DEL_START)\n doc.extend(del_chunks)\n doc.append(DEL_END)\n \ndef cleanup_delete(chunks):\n ''\n\n\n\n\n\n\n \n while 1:\n \n \n \n  try :\n   pre_delete,delete,post_delete=split_delete(chunks)\n  except NoDeletes:\n  \n   break\n   \n   \n  unbalanced_start,balanced,unbalanced_end=split_unbalanced(delete)\n  \n  \n  locate_unbalanced_start(unbalanced_start,pre_delete,post_delete)\n  locate_unbalanced_end(unbalanced_end,pre_delete,post_delete)\n  doc=pre_delete\n  if doc and not doc[-1].endswith(' '):\n  \n   doc[-1]+=' '\n  doc.append('<del>')\n  if balanced and balanced[-1].endswith(' '):\n  \n   balanced[-1]=balanced[-1][:-1]\n  doc.extend(balanced)\n  doc.append('</del> ')\n  doc.extend(post_delete)\n  chunks=doc\n return chunks\n \ndef split_unbalanced(chunks):\n ''\n\n\n\n\n\n \n start=[]\n end=[]\n tag_stack=[]\n balanced=[]\n for chunk in chunks:\n  if not chunk.startswith('<'):\n   balanced.append(chunk)\n   continue\n  endtag=chunk[1]=='/'\n  name=chunk.split()[0].strip('<>/')\n  if name in empty_tags:\n   balanced.append(chunk)\n   continue\n  if endtag:\n   if tag_stack and tag_stack[-1][0]==name:\n    balanced.append(chunk)\n    name,pos,tag=tag_stack.pop()\n    balanced[pos]=tag\n   elif tag_stack:\n    start.extend([tag for name,pos,tag in tag_stack])\n    tag_stack=[]\n    end.append(chunk)\n   else :\n    end.append(chunk)\n  else :\n   tag_stack.append((name,len(balanced),chunk))\n   balanced.append(None )\n start.extend(\n [chunk for name,pos,chunk in tag_stack])\n balanced=[chunk for chunk in balanced if chunk is not None ]\n return start,balanced,end\n \ndef split_delete(chunks):\n ''\n\n\n \n try :\n  pos=chunks.index(DEL_START)\n except ValueError:\n  raise NoDeletes\n pos2=chunks.index(DEL_END)\n return chunks[:pos],chunks[pos+1:pos2],chunks[pos2+1:]\n \ndef locate_unbalanced_start(unbalanced_start,pre_delete,post_delete):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n while 1:\n  if not unbalanced_start:\n  \n   break\n  finding=unbalanced_start[0]\n  finding_name=finding.split()[0].strip('<>')\n  if not post_delete:\n   break\n  next=post_delete[0]\n  if next is DEL_START or not next.startswith('<'):\n  \n   break\n  if next[1]=='/':\n  \n   break\n  name=next.split()[0].strip('<>')\n  if name =='ins':\n  \n   break\n  assert name !='del',(\n  \"Unexpected delete tag: %r\"%next)\n  if name ==finding_name:\n   unbalanced_start.pop(0)\n   pre_delete.append(post_delete.pop(0))\n  else :\n  \n   break\n   \ndef locate_unbalanced_end(unbalanced_end,pre_delete,post_delete):\n ''\n \n while 1:\n  if not unbalanced_end:\n  \n   break\n  finding=unbalanced_end[-1]\n  finding_name=finding.split()[0].strip('<>/')\n  if not pre_delete:\n   break\n  next=pre_delete[-1]\n  if next is DEL_END or not next.startswith('</'):\n  \n   break\n  name=next.split()[0].strip('<>/')\n  if name =='ins'or name =='del':\n  \n   break\n  if name ==finding_name:\n   unbalanced_end.pop()\n   post_delete.insert(0,pre_delete.pop())\n  else :\n  \n   break\n   \nclass token(_unicode):\n ''\n\n\n\n\n\n\n\n\n\n \n \n \n \n hide_when_equal=False\n \n def __new__(cls,text,pre_tags=None ,post_tags=None ,trailing_whitespace=\"\"):\n  obj=_unicode.__new__(cls,text)\n  \n  if pre_tags is not None :\n   obj.pre_tags=pre_tags\n  else :\n   obj.pre_tags=[]\n   \n  if post_tags is not None :\n   obj.post_tags=post_tags\n  else :\n   obj.post_tags=[]\n   \n  obj.trailing_whitespace=trailing_whitespace\n  \n  return obj\n  \n def __repr__(self):\n  return 'token(%s, %r, %r, %r)'%(_unicode.__repr__(self),self.pre_tags,\n  self.post_tags,self.trailing_whitespace)\n  \n def html(self):\n  return _unicode(self)\n  \nclass tag_token(token):\n\n ''\n\n \n \n def __new__(cls,tag,data,html_repr,pre_tags=None ,\n post_tags=None ,trailing_whitespace=\"\"):\n  obj=token.__new__(cls,\"%s: %s\"%(type,data),\n  pre_tags=pre_tags,\n  post_tags=post_tags,\n  trailing_whitespace=trailing_whitespace)\n  obj.tag=tag\n  obj.data=data\n  obj.html_repr=html_repr\n  return obj\n  \n def __repr__(self):\n  return 'tag_token(%s, %s, html_repr=%s, post_tags=%r, pre_tags=%r, trailing_whitespace=%r)'%(\n  self.tag,\n  self.data,\n  self.html_repr,\n  self.pre_tags,\n  self.post_tags,\n  self.trailing_whitespace)\n def html(self):\n  return self.html_repr\n  \nclass href_token(token):\n\n ''\n \n \n hide_when_equal=True\n \n def html(self):\n  return ' Link: %s'%self\n  \ndef tokenize(html,include_hrefs=True ):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n \n if etree.iselement(html):\n  body_el=html\n else :\n  body_el=parse_html(html,cleanup=True )\n  \n chunks=flatten_el(body_el,skip_tag=True ,include_hrefs=include_hrefs)\n \n return fixup_chunks(chunks)\n \ndef parse_html(html,cleanup=True ):\n ''\n\n\n\n\n\n \n if cleanup:\n \n  html=cleanup_html(html)\n return fragment_fromstring(html,create_parent=True )\n \n_body_re=re.compile(r'<body.*?>',re.I |re.S)\n_end_body_re=re.compile(r'</body.*?>',re.I |re.S)\n_ins_del_re=re.compile(r'</?(ins|del).*?>',re.I |re.S)\n\ndef cleanup_html(html):\n ''\n\n \n match=_body_re.search(html)\n if match:\n  html=html[match.end():]\n match=_end_body_re.search(html)\n if match:\n  html=html[:match.start()]\n html=_ins_del_re.sub('',html)\n return html\n \n \nend_whitespace_re=re.compile(r'[ \\t\\n\\r]$')\n\ndef split_trailing_whitespace(word):\n ''\n\n \n stripped_length=len(word.rstrip())\n return word[0:stripped_length],word[stripped_length:]\n \n \ndef fixup_chunks(chunks):\n ''\n\n \n tag_accum=[]\n cur_word=None\n result=[]\n for chunk in chunks:\n  if isinstance(chunk,tuple):\n   if chunk[0]=='img':\n    src=chunk[1]\n    tag,trailing_whitespace=split_trailing_whitespace(chunk[2])\n    cur_word=tag_token('img',src,html_repr=tag,\n    pre_tags=tag_accum,\n    trailing_whitespace=trailing_whitespace)\n    tag_accum=[]\n    result.append(cur_word)\n    \n   elif chunk[0]=='href':\n    href=chunk[1]\n    cur_word=href_token(href,pre_tags=tag_accum,trailing_whitespace=\" \")\n    tag_accum=[]\n    result.append(cur_word)\n   continue\n   \n  if is_word(chunk):\n   chunk,trailing_whitespace=split_trailing_whitespace(chunk)\n   cur_word=token(chunk,pre_tags=tag_accum,trailing_whitespace=trailing_whitespace)\n   tag_accum=[]\n   result.append(cur_word)\n   \n  elif is_start_tag(chunk):\n   tag_accum.append(chunk)\n   \n  elif is_end_tag(chunk):\n   if tag_accum:\n    tag_accum.append(chunk)\n   else :\n    assert cur_word,(\n    \"Weird state, cur_word=%r, result=%r, chunks=%r of %r\"\n    %(cur_word,result,chunk,chunks))\n    cur_word.post_tags.append(chunk)\n  else :\n   assert False\n   \n if not result:\n  return [token('',pre_tags=tag_accum)]\n else :\n  result[-1].post_tags.extend(tag_accum)\n  \n return result\n \n \n \nempty_tags=(\n'param','img','area','br','basefont','input',\n'base','meta','link','col')\n\nblock_level_tags=(\n'address',\n'blockquote',\n'center',\n'dir',\n'div',\n'dl',\n'fieldset',\n'form',\n'h1',\n'h2',\n'h3',\n'h4',\n'h5',\n'h6',\n'hr',\n'isindex',\n'menu',\n'noframes',\n'noscript',\n'ol',\n'p',\n'pre',\n'table',\n'ul',\n)\n\nblock_level_container_tags=(\n'dd',\n'dt',\n'frameset',\n'li',\n'tbody',\n'td',\n'tfoot',\n'th',\n'thead',\n'tr',\n)\n\n\ndef flatten_el(el,include_hrefs,skip_tag=False ):\n ''\n\n\n\n\n \n if not skip_tag:\n  if el.tag =='img':\n   yield ('img',el.get('src'),start_tag(el))\n  else :\n   yield start_tag(el)\n if el.tag in empty_tags and not el.text and not len(el)and not el.tail:\n  return\n start_words=split_words(el.text)\n for word in start_words:\n  yield html_escape(word)\n for child in el:\n  for item in flatten_el(child,include_hrefs=include_hrefs):\n   yield item\n if el.tag =='a'and el.get('href')and include_hrefs:\n  yield ('href',el.get('href'))\n if not skip_tag:\n  yield end_tag(el)\n  end_words=split_words(el.tail)\n  for word in end_words:\n   yield html_escape(word)\n   \nsplit_words_re=re.compile(r'\\S+(?:\\s+|$)',re.U)\n\ndef split_words(text):\n ''\n \n if not text or not text.strip():\n  return []\n  \n words=split_words_re.findall(text)\n return words\n \nstart_whitespace_re=re.compile(r'^[ \\t\\n\\r]')\n\ndef start_tag(el):\n ''\n\n \n return '<%s%s>'%(\n el.tag,''.join([' %s=\"%s\"'%(name,html_escape(value,True ))\n for name,value in el.attrib.items()]))\n \ndef end_tag(el):\n ''\n \n if el.tail and start_whitespace_re.search(el.tail):\n  extra=' '\n else :\n  extra=''\n return '</%s>%s'%(el.tag,extra)\n \ndef is_word(tok):\n return not tok.startswith('<')\n \ndef is_end_tag(tok):\n return tok.startswith('</')\n \ndef is_start_tag(tok):\n return tok.startswith('<')and not tok.startswith('</')\n \ndef fixup_ins_del_tags(html):\n ''\n\n \n doc=parse_html(html,cleanup=False )\n _fixup_ins_del_tags(doc)\n html=serialize_html_fragment(doc,skip_outer=True )\n return html\n \ndef serialize_html_fragment(el,skip_outer=False ):\n ''\n\n\n\n \n assert not isinstance(el,basestring),(\n \"You should pass in an element, not a string like %r\"%el)\n html=etree.tostring(el,method=\"html\",encoding=_unicode)\n if skip_outer:\n \n  html=html[html.find('>')+1:]\n  \n  html=html[:html.rfind('<')]\n  return html.strip()\n else :\n  return html\n  \ndef _fixup_ins_del_tags(doc):\n ''\n \n for tag in ['ins','del']:\n  for el in doc.xpath('descendant-or-self::%s'%tag):\n   if not _contains_block_level_tag(el):\n    continue\n   _move_el_inside_block(el,tag=tag)\n   el.drop_tag()\n   \n   \ndef _contains_block_level_tag(el):\n ''\n \n if el.tag in block_level_tags or el.tag in block_level_container_tags:\n  return True\n for child in el:\n  if _contains_block_level_tag(child):\n   return True\n return False\n \ndef _move_el_inside_block(el,tag):\n ''\n \n for child in el:\n  if _contains_block_level_tag(child):\n   break\n else :\n \n  children_tag=etree.Element(tag)\n  children_tag.text=el.text\n  el.text=None\n  children_tag.extend(list(el))\n  el[:]=[children_tag]\n  return\n for child in list(el):\n  if _contains_block_level_tag(child):\n   _move_el_inside_block(child,tag)\n   if child.tail:\n    tail_tag=etree.Element(tag)\n    tail_tag.text=child.tail\n    child.tail=None\n    el.insert(el.index(child)+1,tail_tag)\n  else :\n   child_tag=etree.Element(tag)\n   el.replace(child,child_tag)\n   child_tag.append(child)\n if el.text:\n  text_tag=etree.Element(tag)\n  text_tag.text=el.text\n  el.text=None\n  el.insert(0,text_tag)\n  \ndef _merge_element_contents(el):\n ''\n\n\n\n \n parent=el.getparent()\n text=el.text or ''\n if el.tail:\n  if not len(el):\n   text +=el.tail\n  else :\n   if el[-1].tail:\n    el[-1].tail +=el.tail\n   else :\n    el[-1].tail=el.tail\n index=parent.index(el)\n if text:\n  if index ==0:\n   previous=None\n  else :\n   previous=parent[index -1]\n  if previous is None :\n   if parent.text:\n    parent.text +=text\n   else :\n    parent.text=text\n  else :\n   if previous.tail:\n    previous.tail +=text\n   else :\n    previous.tail=text\n parent[index:index+1]=el.getchildren()\n \nclass InsensitiveSequenceMatcher(difflib.SequenceMatcher):\n ''\n\n\n \n \n threshold=2\n \n def get_matching_blocks(self):\n  size=min(len(self.b),len(self.b))\n  threshold=min(self.threshold,size /4)\n  actual=difflib.SequenceMatcher.get_matching_blocks(self)\n  return [item for item in actual\n  if item[2]>threshold\n  or not item[2]]\n  \nif __name__ =='__main__':\n from lxml.html import _diffcommand\n _diffcommand.main()\n \n", ["__future__", "cgi", "difflib", "html", "lxml", "lxml.html", "re"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.ElementSoup": [".py", "__doc__=\"\"\"Legacy interface to the BeautifulSoup HTML parser.\n\"\"\"\n\n__all__=[\"parse\",\"convert_tree\"]\n\nfrom .soupparser import convert_tree,parse as _parse\n\ndef parse(file,beautifulsoup=None ,makeelement=None ):\n root=_parse(file,beautifulsoup=beautifulsoup,makeelement=makeelement)\n return root.getroot()\n", ["bpmn2camel.camel_dsl.Json2Camel.lxml.html.soupparser"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.formfill": [".py", "from lxml.etree import XPath,ElementBase\nfrom lxml.html import fromstring,XHTML_NAMESPACE\nfrom lxml.html import _forms_xpath,_options_xpath,_nons,_transform_result\nfrom lxml.html import defs\nimport copy\n\ntry :\n basestring\nexcept NameError:\n\n basestring=str\n \n__all__=['FormNotFound','fill_form','fill_form_html',\n'insert_errors','insert_errors_html',\n'DefaultErrorCreator']\n\nclass FormNotFound(LookupError):\n ''\n\n \n \n_form_name_xpath=XPath('descendant-or-self::form[name=$name]|descendant-or-self::x:form[name=$name]',namespaces={'x':XHTML_NAMESPACE})\n_input_xpath=XPath('|'.join(['descendant-or-self::'+_tag for _tag in ('input','select','textarea','x:input','x:select','x:textarea')]),\nnamespaces={'x':XHTML_NAMESPACE})\n_label_for_xpath=XPath('//label[@for=$for_id]|//x:label[@for=$for_id]',\nnamespaces={'x':XHTML_NAMESPACE})\n_name_xpath=XPath('descendant-or-self::*[@name=$name]')\n\ndef fill_form(\nel,\nvalues,\nform_id=None ,\nform_index=None ,\n):\n el=_find_form(el,form_id=form_id,form_index=form_index)\n _fill_form(el,values)\n \ndef fill_form_html(html,values,form_id=None ,form_index=None ):\n result_type=type(html)\n if isinstance(html,basestring):\n  doc=fromstring(html)\n else :\n  doc=copy.deepcopy(html)\n fill_form(doc,values,form_id=form_id,form_index=form_index)\n return _transform_result(result_type,doc)\n \ndef _fill_form(el,values):\n counts={}\n if hasattr(values,'mixed'):\n \n  values=values.mixed()\n inputs=_input_xpath(el)\n for input in inputs:\n  name=input.get('name')\n  if not name:\n   continue\n  if _takes_multiple(input):\n   value=values.get(name,[])\n   if not isinstance(value,(list,tuple)):\n    value=[value]\n   _fill_multiple(input,value)\n  elif name not in values:\n   continue\n  else :\n   index=counts.get(name,0)\n   counts[name]=index+1\n   value=values[name]\n   if isinstance(value,(list,tuple)):\n    try :\n     value=value[index]\n    except IndexError:\n     continue\n   elif index >0:\n    continue\n   _fill_single(input,value)\n   \ndef _takes_multiple(input):\n if _nons(input.tag)=='select'and input.get('multiple'):\n \n  return True\n type=input.get('type','').lower()\n if type in ('radio','checkbox'):\n  return True\n return False\n \ndef _fill_multiple(input,value):\n type=input.get('type','').lower()\n if type =='checkbox':\n  v=input.get('value')\n  if v is None :\n   if not value:\n    result=False\n   else :\n    result=value[0]\n    if isinstance(value,basestring):\n    \n     result=result =='on'\n   _check(input,result)\n  else :\n   _check(input,v in value)\n elif type =='radio':\n  v=input.get('value')\n  _check(input,v in value)\n else :\n  assert _nons(input.tag)=='select'\n  for option in _options_xpath(input):\n   v=option.get('value')\n   if v is None :\n   \n   \n    v=option.text_content()\n   _select(option,v in value)\n   \ndef _check(el,check):\n if check:\n  el.set('checked','')\n else :\n  if 'checked'in el.attrib:\n   del el.attrib['checked']\n   \ndef _select(el,select):\n if select:\n  el.set('selected','')\n else :\n  if 'selected'in el.attrib:\n   del el.attrib['selected']\n   \ndef _fill_single(input,value):\n if _nons(input.tag)=='textarea':\n  input.text=value\n else :\n  input.set('value',value)\n  \ndef _find_form(el,form_id=None ,form_index=None ):\n if form_id is None and form_index is None :\n  forms=_forms_xpath(el)\n  for form in forms:\n   return form\n  raise FormNotFound(\n  \"No forms in page\")\n if form_id is not None :\n  form=el.get_element_by_id(form_id)\n  if form is not None :\n   return form\n  forms=_form_name_xpath(el,name=form_id)\n  if forms:\n   return forms[0]\n  else :\n   raise FormNotFound(\n   \"No form with the name or id of %r (forms: %s)\"\n   %(id,', '.join(_find_form_ids(el))))\n if form_index is not None :\n  forms=_forms_xpath(el)\n  try :\n   return forms[form_index]\n  except IndexError:\n   raise FormNotFound(\n   \"There is no form with the index %r (%i forms found)\"\n   %(form_index,len(forms)))\n   \ndef _find_form_ids(el):\n forms=_forms_xpath(el)\n if not forms:\n  yield '(no forms)'\n  return\n for index,form in enumerate(forms):\n  if form.get('id'):\n   if form.get('name'):\n    yield '%s or %s'%(form.get('id'),\n    form.get('name'))\n   else :\n    yield form.get('id')\n  elif form.get('name'):\n   yield form.get('name')\n  else :\n   yield '(unnamed form %s)'%index\n   \n   \n   \n   \n   \nclass DefaultErrorCreator(object):\n insert_before=True\n block_inside=True\n error_container_tag='div'\n error_message_class='error-message'\n error_block_class='error-block'\n default_message=\"Invalid\"\n \n def __init__(self,**kw):\n  for name,value in kw.items():\n   if not hasattr(self,name):\n    raise TypeError(\n    \"Unexpected keyword argument: %s\"%name)\n   setattr(self,name,value)\n   \n def __call__(self,el,is_block,message):\n  error_el=el.makeelement(self.error_container_tag)\n  if self.error_message_class:\n   error_el.set('class',self.error_message_class)\n  if is_block and self.error_block_class:\n   error_el.set('class',error_el.get('class','')+' '+self.error_block_class)\n  if message is None or message =='':\n   message=self.default_message\n  if isinstance(message,ElementBase):\n   error_el.append(message)\n  else :\n   assert isinstance(message,basestring),(\n   \"Bad message; should be a string or element: %r\"%message)\n   error_el.text=message or self.default_message\n  if is_block and self.block_inside:\n   if self.insert_before:\n    error_el.tail=el.text\n    el.text=None\n    el.insert(0,error_el)\n   else :\n    el.append(error_el)\n  else :\n   parent=el.getparent()\n   pos=parent.index(el)\n   if self.insert_before:\n    parent.insert(pos,error_el)\n   else :\n    error_el.tail=el.tail\n    el.tail=None\n    parent.insert(pos+1,error_el)\n    \ndefault_error_creator=DefaultErrorCreator()\n\n\ndef insert_errors(\nel,\nerrors,\nform_id=None ,\nform_index=None ,\nerror_class=\"error\",\nerror_creator=default_error_creator,\n):\n el=_find_form(el,form_id=form_id,form_index=form_index)\n for name,error in errors.items():\n  if error is None :\n   continue\n  for error_el,message in _find_elements_for_name(el,name,error):\n   assert isinstance(message,(basestring,type(None ),ElementBase)),(\n   \"Bad message: %r\"%message)\n   _insert_error(error_el,message,error_class,error_creator)\n   \ndef insert_errors_html(html,values,**kw):\n result_type=type(html)\n if isinstance(html,basestring):\n  doc=fromstring(html)\n else :\n  doc=copy.deepcopy(html)\n insert_errors(doc,values,**kw)\n return _transform_result(result_type,doc)\n \ndef _insert_error(el,error,error_class,error_creator):\n if _nons(el.tag)in defs.empty_tags or _nons(el.tag)=='textarea':\n  is_block=False\n else :\n  is_block=True\n if _nons(el.tag)!='form'and error_class:\n  _add_class(el,error_class)\n if el.get('id'):\n  labels=_label_for_xpath(el,for_id=el.get('id'))\n  if labels:\n   for label in labels:\n    _add_class(label,error_class)\n error_creator(el,is_block,error)\n \ndef _add_class(el,class_name):\n if el.get('class'):\n  el.set('class',el.get('class')+' '+class_name)\n else :\n  el.set('class',class_name)\n  \ndef _find_elements_for_name(form,name,error):\n if name is None :\n \n  yield form,error\n  return\n if name.startswith('#'):\n \n  el=form.get_element_by_id(name[1:])\n  if el is not None :\n   yield el,error\n  return\n els=_name_xpath(form,name=name)\n if not els:\n \n  return\n if not isinstance(error,(list,tuple)):\n  yield els[0],error\n  return\n  \n for el,err in zip(els,error):\n  if err is None :\n   continue\n  yield el,err\n", ["copy", "lxml.etree", "lxml.html"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.html5parser": [".py", "''\n\n\nimport sys\nimport string\n\nfrom html5lib import HTMLParser as _HTMLParser\nfrom html5lib.treebuilders.etree_lxml import TreeBuilder\nfrom lxml import etree\nfrom lxml.html import Element,XHTML_NAMESPACE,_contains_block_level_tag\n\n\ntry :\n _strings=basestring\nexcept NameError:\n _strings=(bytes,str)\ntry :\n from urllib2 import urlopen\nexcept ImportError:\n from urllib.request import urlopen\ntry :\n from urlparse import urlparse\nexcept ImportError:\n from urllib.parse import urlparse\n \n \nclass HTMLParser(_HTMLParser):\n ''\n \n def __init__(self,strict=False ,**kwargs):\n  _HTMLParser.__init__(self,strict=strict,tree=TreeBuilder,**kwargs)\n  \n  \ntry :\n from html5lib import XHTMLParser as _XHTMLParser\nexcept ImportError:\n pass\nelse :\n class XHTMLParser(_XHTMLParser):\n  ''\n  \n  def __init__(self,strict=False ,**kwargs):\n   _XHTMLParser.__init__(self,strict=strict,tree=TreeBuilder,**kwargs)\n   \n xhtml_parser=XHTMLParser()\n \n \ndef _find_tag(tree,tag):\n elem=tree.find(tag)\n if elem is not None :\n  return elem\n return tree.find('{%s}%s'%(XHTML_NAMESPACE,tag))\n \n \ndef document_fromstring(html,guess_charset=None ,parser=None ):\n ''\n\n\n\n\n\n \n if not isinstance(html,_strings):\n  raise TypeError('string required')\n  \n if parser is None :\n  parser=html_parser\n  \n options={}\n if guess_charset is None and isinstance(html,bytes):\n \n \n  guess_charset=True\n if guess_charset is not None :\n  options['useChardet']=guess_charset\n return parser.parse(html,**options).getroot()\n \n \ndef fragments_fromstring(html,no_leading_text=False ,\nguess_charset=None ,parser=None ):\n ''\n\n\n\n\n\n\n\n \n if not isinstance(html,_strings):\n  raise TypeError('string required')\n  \n if parser is None :\n  parser=html_parser\n  \n options={}\n if guess_charset is None and isinstance(html,bytes):\n \n \n  guess_charset=False\n if guess_charset is not None :\n  options['useChardet']=guess_charset\n children=parser.parseFragment(html,'div',**options)\n if children and isinstance(children[0],_strings):\n  if no_leading_text:\n   if children[0].strip():\n    raise etree.ParserError('There is leading text: %r'%\n    children[0])\n   del children[0]\n return children\n \n \ndef fragment_fromstring(html,create_parent=False ,\nguess_charset=None ,parser=None ):\n ''\n\n\n\n\n\n\n\n\n\n \n if not isinstance(html,_strings):\n  raise TypeError('string required')\n  \n accept_leading_text=bool(create_parent)\n \n elements=fragments_fromstring(\n html,guess_charset=guess_charset,parser=parser,\n no_leading_text=not accept_leading_text)\n \n if create_parent:\n  if not isinstance(create_parent,_strings):\n   create_parent='div'\n  new_root=Element(create_parent)\n  if elements:\n   if isinstance(elements[0],_strings):\n    new_root.text=elements[0]\n    del elements[0]\n   new_root.extend(elements)\n  return new_root\n  \n if not elements:\n  raise etree.ParserError('No elements found')\n if len(elements)>1:\n  raise etree.ParserError('Multiple elements found')\n result=elements[0]\n if result.tail and result.tail.strip():\n  raise etree.ParserError('Element followed by text: %r'%result.tail)\n result.tail=None\n return result\n \n \ndef fromstring(html,guess_charset=None ,parser=None ):\n ''\n\n\n\n\n\n\n\n\n\n\n \n if not isinstance(html,_strings):\n  raise TypeError('string required')\n doc=document_fromstring(html,parser=parser,\n guess_charset=guess_charset)\n \n \n start=html[:50]\n if isinstance(start,bytes):\n \n \n \n  start=start.decode('ascii','replace')\n  \n start=start.lstrip().lower()\n if start.startswith('<html')or start.startswith('<!doctype'):\n  return doc\n  \n head=_find_tag(doc,'head')\n \n \n if len(head):\n  return doc\n  \n body=_find_tag(doc,'body')\n \n \n \n if (len(body)==1 and (not body.text or not body.text.strip())\n and (not body[-1].tail or not body[-1].tail.strip())):\n  return body[0]\n  \n  \n  \n  \n if _contains_block_level_tag(body):\n  body.tag='div'\n else :\n  body.tag='span'\n return body\n \n \ndef parse(filename_url_or_file,guess_charset=None ,parser=None ):\n ''\n\n\n\n\n\n\n\n\n \n if parser is None :\n  parser=html_parser\n if not isinstance(filename_url_or_file,_strings):\n  fp=filename_url_or_file\n  if guess_charset is None :\n  \n   guess_charset=False\n elif _looks_like_url(filename_url_or_file):\n  fp=urlopen(filename_url_or_file)\n  if guess_charset is None :\n  \n   guess_charset=True\n else :\n  fp=open(filename_url_or_file,'rb')\n  if guess_charset is None :\n   guess_charset=True\n   \n options={}\n \n \n if guess_charset:\n  options['useChardet']=guess_charset\n return parser.parse(fp,**options)\n \n \ndef _looks_like_url(str):\n scheme=urlparse(str)[0]\n if not scheme:\n  return False\n elif (sys.platform =='win32'and\n scheme in string.ascii_letters\n and len(scheme)==1):\n \n  return False\n else :\n  return True\n  \n  \nhtml_parser=HTMLParser()\n", ["html5lib", "html5lib.treebuilders.etree_lxml", "lxml", "lxml.html", "string", "sys", "urllib.parse", "urllib.request", "urllib2", "urlparse"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.soupparser": [".py", "''\n\n\n__all__=[\"fromstring\",\"parse\",\"convert_tree\"]\n\nimport re\nfrom lxml import etree,html\n\ntry :\n from bs4 import (\n BeautifulSoup,Tag,Comment,ProcessingInstruction,NavigableString,\n Declaration,Doctype)\n _DECLARATION_OR_DOCTYPE=(Declaration,Doctype)\nexcept ImportError:\n from BeautifulSoup import (\n BeautifulSoup,Tag,Comment,ProcessingInstruction,NavigableString,\n Declaration)\n _DECLARATION_OR_DOCTYPE=Declaration\n \n \ndef fromstring(data,beautifulsoup=None ,makeelement=None ,**bsargs):\n ''\n\n\n\n\n\n\n\n\n\n \n return _parse(data,beautifulsoup,makeelement,**bsargs)\n \n \ndef parse(file,beautifulsoup=None ,makeelement=None ,**bsargs):\n ''\n\n\n\n\n\n\n \n if not hasattr(file,'read'):\n  file=open(file)\n root=_parse(file,beautifulsoup,makeelement,**bsargs)\n return etree.ElementTree(root)\n \n \ndef convert_tree(beautiful_soup_tree,makeelement=None ):\n ''\n\n\n\n\n\n\n \n root=_convert_tree(beautiful_soup_tree,makeelement)\n children=root.getchildren()\n for child in children:\n  root.remove(child)\n return children\n \n \n \n \ndef _parse(source,beautifulsoup,makeelement,**bsargs):\n if beautifulsoup is None :\n  beautifulsoup=BeautifulSoup\n if hasattr(beautifulsoup,\"HTML_ENTITIES\"):\n  if 'convertEntities'not in bsargs:\n   bsargs['convertEntities']='html'\n if hasattr(beautifulsoup,\"DEFAULT_BUILDER_FEATURES\"):\n  if 'features'not in bsargs:\n   bsargs['features']='html.parser'\n tree=beautifulsoup(source,**bsargs)\n root=_convert_tree(tree,makeelement)\n \n if len(root)==1 and root[0].tag ==\"html\":\n  return root[0]\n root.tag=\"html\"\n return root\n \n \n_parse_doctype_declaration=re.compile(\nr'(?:\\s|[<!])*DOCTYPE\\s*HTML'\nr'(?:\\s+PUBLIC)?(?:\\s+(\\'[^\\']*\\'|\"[^\"]*\"))?'\nr'(?:\\s+(\\'[^\\']*\\'|\"[^\"]*\"))?',\nre.IGNORECASE).match\n\n\nclass _PseudoTag:\n\n def __init__(self,contents):\n  self.name='html'\n  self.attrs=[]\n  self.contents=contents\n  \n def __iter__(self):\n  return self.contents.__iter__()\n  \n  \ndef _convert_tree(beautiful_soup_tree,makeelement):\n if makeelement is None :\n  makeelement=html.html_parser.makeelement\n  \n  \n  \n  \n  \n  \n  \n first_element_idx=last_element_idx=None\n html_root=declaration=None\n for i,e in enumerate(beautiful_soup_tree):\n  if isinstance(e,Tag):\n   if first_element_idx is None :\n    first_element_idx=i\n   last_element_idx=i\n   if html_root is None and e.name and e.name.lower()=='html':\n    html_root=e\n  elif declaration is None and isinstance(e,_DECLARATION_OR_DOCTYPE):\n   declaration=e\n   \n   \n   \n   \n   \n   \n if first_element_idx is None :\n  pre_root=post_root=[]\n  roots=beautiful_soup_tree.contents\n else :\n  pre_root=beautiful_soup_tree.contents[:first_element_idx]\n  roots=beautiful_soup_tree.contents[first_element_idx:last_element_idx+1]\n  post_root=beautiful_soup_tree.contents[last_element_idx+1:]\n  \n  \n if html_root is not None :\n \n  i=roots.index(html_root)\n  html_root.contents=roots[:i]+html_root.contents+roots[i+1:]\n else :\n \n  html_root=_PseudoTag(roots)\n  \n convert_node=_init_node_converters(makeelement)\n \n \n res_root=convert_node(html_root)\n prev=res_root\n for e in reversed(pre_root):\n  converted=convert_node(e)\n  if converted is not None :\n   prev.addprevious(converted)\n   prev=converted\n   \n   \n prev=res_root\n for e in post_root:\n  converted=convert_node(e)\n  if converted is not None :\n   prev.addnext(converted)\n   prev=converted\n   \n if declaration is not None :\n  try :\n  \n   doctype_string=declaration.output_ready()\n  except AttributeError:\n   doctype_string=declaration.string\n   \n  match=_parse_doctype_declaration(doctype_string)\n  if not match:\n  \n  \n   pass\n  else :\n   external_id,sys_uri=match.groups()\n   docinfo=res_root.getroottree().docinfo\n   \n   docinfo.public_id=external_id and external_id[1:-1]\n   docinfo.system_url=sys_uri and sys_uri[1:-1]\n   \n return res_root\n \n \ndef _init_node_converters(makeelement):\n converters={}\n ordered_node_types=[]\n \n def converter(*types):\n  def add(handler):\n   for t in types:\n    converters[t]=handler\n    ordered_node_types.append(t)\n   return handler\n  return add\n  \n def find_best_converter(node):\n  for t in ordered_node_types:\n   if isinstance(node,t):\n    return converters[t]\n  return None\n  \n def convert_node(bs_node,parent=None ):\n \n  try :\n   handler=converters[type(bs_node)]\n  except KeyError:\n   handler=converters[type(bs_node)]=find_best_converter(bs_node)\n  if handler is None :\n   return None\n  return handler(bs_node,parent)\n  \n def map_attrs(bs_attrs):\n  if isinstance(bs_attrs,dict):\n   attribs={}\n   for k,v in bs_attrs.items():\n    if isinstance(v,list):\n     v=\" \".join(v)\n    attribs[k]=unescape(v)\n  else :\n   attribs=dict((k,unescape(v))for k,v in bs_attrs)\n  return attribs\n  \n def append_text(parent,text):\n  if len(parent)==0:\n   parent.text=(parent.text or '')+text\n  else :\n   parent[-1].tail=(parent[-1].tail or '')+text\n   \n   \n   \n @converter(Tag,_PseudoTag)\n def convert_tag(bs_node,parent):\n  attrs=bs_node.attrs\n  if parent is not None :\n   attribs=map_attrs(attrs)if attrs else None\n   res=etree.SubElement(parent,bs_node.name,attrib=attribs)\n  else :\n   attribs=map_attrs(attrs)if attrs else {}\n   res=makeelement(bs_node.name,attrib=attribs)\n   \n  for child in bs_node:\n  \n   try :\n    handler=converters[type(child)]\n   except KeyError:\n    pass\n   else :\n    if handler is not None :\n     handler(child,res)\n    continue\n   convert_node(child,res)\n  return res\n  \n @converter(Comment)\n def convert_comment(bs_node,parent):\n  res=html.HtmlComment(bs_node)\n  if parent is not None :\n   parent.append(res)\n  return res\n  \n @converter(ProcessingInstruction)\n def convert_pi(bs_node,parent):\n  if bs_node.endswith('?'):\n  \n  \n   bs_node=bs_node[:-1]\n  res=etree.ProcessingInstruction(*bs_node.split(' ',1))\n  if parent is not None :\n   parent.append(res)\n  return res\n  \n @converter(NavigableString)\n def convert_text(bs_node,parent):\n  if parent is not None :\n   append_text(parent,unescape(bs_node))\n  return None\n  \n return convert_node\n \n \n \n \ntry :\n from html.entities import name2codepoint\nexcept ImportError:\n from htmlentitydefs import name2codepoint\n \n \nhandle_entities=re.compile(r\"&(\\w+);\").sub\n\n\ntry :\n unichr\nexcept NameError:\n\n unichr=chr\n \n \ndef unescape(string):\n if not string:\n  return ''\n  \n def unescape_entity(m):\n  try :\n   return unichr(name2codepoint[m.group(1)])\n  except KeyError:\n   return m.group(0)\n return handle_entities(unescape_entity,string)\n", ["BeautifulSoup", "bs4", "html.entities", "htmlentitydefs", "lxml", "re"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html.usedoctest": [".py", "''\n\n\n\n\n\n\n\n\n\nfrom lxml import doctestcompare\n\ndoctestcompare.temp_install(html=True ,del_module=__name__)\n", ["lxml"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html._diffcommand": [".py", "from __future__ import absolute_import\n\nimport optparse\nimport sys\nimport re\nimport os\nfrom .diff import htmldiff\n\ndescription=\"\"\"\\\n\"\"\"\n\nparser=optparse.OptionParser(\nusage=\"%prog [OPTIONS] FILE1 FILE2\\n\"\n\"%prog --annotate [OPTIONS] INFO1 FILE1 INFO2 FILE2 ...\",\ndescription=description,\n)\n\nparser.add_option(\n'-o','--output',\nmetavar=\"FILE\",\ndest=\"output\",\ndefault=\"-\",\nhelp=\"File to write the difference to\",\n)\n\nparser.add_option(\n'-a','--annotation',\naction=\"store_true\",\ndest=\"annotation\",\nhelp=\"Do an annotation\")\n\ndef main(args=None ):\n if args is None :\n  args=sys.argv[1:]\n options,args=parser.parse_args(args)\n if options.annotation:\n  return annotate(options,args)\n if len(args)!=2:\n  print('Error: you must give two files')\n  parser.print_help()\n  sys.exit(1)\n file1,file2=args\n input1=read_file(file1)\n input2=read_file(file2)\n body1=split_body(input1)[1]\n pre,body2,post=split_body(input2)\n result=htmldiff(body1,body2)\n result=pre+result+post\n if options.output =='-':\n  if not result.endswith('\\n'):\n   result +='\\n'\n  sys.stdout.write(result)\n else :\n  with open(options.output,'wb')as f:\n   f.write(result)\n   \ndef read_file(filename):\n if filename =='-':\n  c=sys.stdin.read()\n elif not os.path.exists(filename):\n  raise OSError(\n  \"Input file %s does not exist\"%filename)\n else :\n  with open(filename,'rb')as f:\n   c=f.read()\n return c\n \nbody_start_re=re.compile(\nr\"<body.*?>\",re.I |re.S)\nbody_end_re=re.compile(\nr\"</body.*?>\",re.I |re.S)\n\ndef split_body(html):\n pre=post=''\n match=body_start_re.search(html)\n if match:\n  pre=html[:match.end()]\n  html=html[match.end():]\n match=body_end_re.search(html)\n if match:\n  post=html[match.start():]\n  html=html[:match.start()]\n return pre,html,post\n \ndef annotate(options,args):\n print(\"Not yet implemented\")\n sys.exit(1)\n \n", ["__future__", "bpmn2camel.camel_dsl.Json2Camel.lxml.html.diff", "optparse", "os", "re", "sys"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html._html5builder": [".py", "''\n\n\n\n\n\n\n\n\n\nfrom html5lib.treebuilders import _base,etree as etree_builders\nfrom lxml import html,etree\n\n\nclass DocumentType(object):\n\n def __init__(self,name,publicId,systemId):\n  self.name=name\n  self.publicId=publicId\n  self.systemId=systemId\n  \nclass Document(object):\n\n def __init__(self):\n  self._elementTree=None\n  self.childNodes=[]\n  \n def appendChild(self,element):\n  self._elementTree.getroot().addnext(element._element)\n  \n  \nclass TreeBuilder(_base.TreeBuilder):\n documentClass=Document\n doctypeClass=DocumentType\n elementClass=None\n commentClass=None\n fragmentClass=Document\n \n def __init__(self,*args,**kwargs):\n  html_builder=etree_builders.getETreeModule(html,fullTree=False )\n  etree_builder=etree_builders.getETreeModule(etree,fullTree=False )\n  self.elementClass=html_builder.Element\n  self.commentClass=etree_builder.Comment\n  _base.TreeBuilder.__init__(self,*args,**kwargs)\n  \n def reset(self):\n  _base.TreeBuilder.reset(self)\n  self.rootInserted=False\n  self.initialComments=[]\n  self.doctype=None\n  \n def getDocument(self):\n  return self.document._elementTree\n  \n def getFragment(self):\n  fragment=[]\n  element=self.openElements[0]._element\n  if element.text:\n   fragment.append(element.text)\n  fragment.extend(element.getchildren())\n  if element.tail:\n   fragment.append(element.tail)\n  return fragment\n  \n def insertDoctype(self,name,publicId,systemId):\n  doctype=self.doctypeClass(name,publicId,systemId)\n  self.doctype=doctype\n  \n def insertComment(self,data,parent=None ):\n  if not self.rootInserted:\n   self.initialComments.append(data)\n  else :\n   _base.TreeBuilder.insertComment(self,data,parent)\n   \n def insertRoot(self,name):\n  buf=[]\n  if self.doctype and self.doctype.name:\n   buf.append('<!DOCTYPE %s'%self.doctype.name)\n   if self.doctype.publicId is not None or self.doctype.systemId is not None :\n    buf.append(' PUBLIC \"%s\" \"%s\"'%(self.doctype.publicId,\n    self.doctype.systemId))\n   buf.append('>')\n  buf.append('<html></html>')\n  root=html.fromstring(''.join(buf))\n  \n  \n  for comment in self.initialComments:\n   root.addprevious(etree.Comment(comment))\n   \n   \n  self.document=self.documentClass()\n  self.document._elementTree=root.getroottree()\n  \n  \n  root_element=self.elementClass(name)\n  root_element._element=root\n  self.document.childNodes.append(root_element)\n  self.openElements.append(root_element)\n  \n  self.rootInserted=True\n", ["html5lib.treebuilders", "lxml"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html._setmixin": [".py", "try :\n from collections.abc import MutableSet\nexcept ImportError:\n from collections import MutableSet\n \n \nclass SetMixin(MutableSet):\n\n ''\n\n \n \n def __len__(self):\n  length=0\n  for item in self:\n   length +=1\n  return length\n  \n def __contains__(self,item):\n  for has_item in self:\n   if item ==has_item:\n    return True\n  return False\n  \n issubset=MutableSet.__le__\n issuperset=MutableSet.__ge__\n \n union=MutableSet.__or__\n intersection=MutableSet.__and__\n difference=MutableSet.__sub__\n symmetric_difference=MutableSet.__xor__\n \n def copy(self):\n  return set(self)\n  \n def update(self,other):\n  self |=other\n  \n def intersection_update(self,other):\n  self &=other\n  \n def difference_update(self,other):\n  self -=other\n  \n def symmetric_difference_update(self,other):\n  self ^=other\n  \n def discard(self,item):\n  try :\n   self.remove(item)\n  except KeyError:\n   pass\n   \n @classmethod\n def _from_iterable(cls,it):\n  return set(it)\n", ["collections", "collections.abc"]], "bpmn2camel.camel_dsl.Json2Camel.lxml.html": [".py", "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\"The ``lxml.html`` tool set for HTML handling.\n\"\"\"\n\nfrom __future__ import absolute_import\n\n__all__=[\n'document_fromstring','fragment_fromstring','fragments_fromstring','fromstring',\n'tostring','Element','defs','open_in_browser','submit_form',\n'find_rel_links','find_class','make_links_absolute',\n'resolve_base_href','iterlinks','rewrite_links','parse']\n\n\nimport copy\nimport sys\nimport re\nfrom functools import partial\n\ntry :\n from collections.abc import MutableMapping,MutableSet\nexcept ImportError:\n from collections import MutableMapping,MutableSet\n \nfrom .. import etree\nfrom . import defs\nfrom ._setmixin import SetMixin\n\ntry :\n from urlparse import urljoin\nexcept ImportError:\n\n from urllib.parse import urljoin\n \ntry :\n unicode\nexcept NameError:\n\n unicode=str\ntry :\n basestring\nexcept NameError:\n\n basestring=(str,bytes)\n \n \ndef __fix_docstring(s):\n if not s:\n  return s\n if sys.version_info[0]>=3:\n  sub=re.compile(r\"^(\\s*)u'\",re.M).sub\n else :\n  sub=re.compile(r\"^(\\s*)b'\",re.M).sub\n return sub(r\"\\1'\",s)\n \n \nXHTML_NAMESPACE=\"http://www.w3.org/1999/xhtml\"\n\n_rel_links_xpath=etree.XPath(\"descendant-or-self::a[@rel]|descendant-or-self::x:a[@rel]\",\nnamespaces={'x':XHTML_NAMESPACE})\n_options_xpath=etree.XPath(\"descendant-or-self::option|descendant-or-self::x:option\",\nnamespaces={'x':XHTML_NAMESPACE})\n_forms_xpath=etree.XPath(\"descendant-or-self::form|descendant-or-self::x:form\",\nnamespaces={'x':XHTML_NAMESPACE})\n\n_class_xpath=etree.XPath(\"descendant-or-self::*[@class and contains(concat(' ', normalize-space(@class), ' '), concat(' ', $class_name, ' '))]\")\n_id_xpath=etree.XPath(\"descendant-or-self::*[@id=$id]\")\n_collect_string_content=etree.XPath(\"string()\")\n_iter_css_urls=re.compile(r'url\\(('+'[\"][^\"]*[\"]|'+\"['][^']*[']|\"+r'[^)]*)\\)',re.I).finditer\n_iter_css_imports=re.compile(r'@import \"(.*?)\"').finditer\n_label_xpath=etree.XPath(\"//label[@for=$id]|//x:label[@for=$id]\",\nnamespaces={'x':XHTML_NAMESPACE})\n_archive_re=re.compile(r'[^ ]+')\n_parse_meta_refresh_url=re.compile(\nr'[^;=]*;\\s*(?:url\\s*=\\s*)?(?P<url>.*)$',re.I).search\n\n\ndef _unquote_match(s,pos):\n if s[:1]=='\"'and s[-1:]=='\"'or s[:1]==\"'\"and s[-1:]==\"'\":\n  return s[1:-1],pos+1\n else :\n  return s,pos\n  \n  \ndef _transform_result(typ,result):\n ''\n \n if issubclass(typ,bytes):\n  return tostring(result,encoding='utf-8')\n elif issubclass(typ,unicode):\n  return tostring(result,encoding='unicode')\n else :\n  return result\n  \n  \ndef _nons(tag):\n if isinstance(tag,basestring):\n  if tag[0]=='{'and tag[1:len(XHTML_NAMESPACE)+1]==XHTML_NAMESPACE:\n   return tag.split('}')[-1]\n return tag\n \n \nclass Classes(MutableSet):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n def __init__(self,attributes):\n  self._attributes=attributes\n  self._get_class_value=partial(attributes.get,'class','')\n  \n def add(self,value):\n  ''\n\n\n\n  \n  if not value or re.search(r'\\s',value):\n   raise ValueError(\"Invalid class name: %r\"%value)\n  classes=self._get_class_value().split()\n  if value in classes:\n   return\n  classes.append(value)\n  self._attributes['class']=' '.join(classes)\n  \n def discard(self,value):\n  ''\n\n\n\n  \n  if not value or re.search(r'\\s',value):\n   raise ValueError(\"Invalid class name: %r\"%value)\n  classes=[name for name in self._get_class_value().split()\n  if name !=value]\n  if classes:\n   self._attributes['class']=' '.join(classes)\n  elif 'class'in self._attributes:\n   del self._attributes['class']\n   \n def remove(self,value):\n  ''\n\n\n\n  \n  if not value or re.search(r'\\s',value):\n   raise ValueError(\"Invalid class name: %r\"%value)\n  super(Classes,self).remove(value)\n  \n def __contains__(self,name):\n  classes=self._get_class_value()\n  return name in classes and name in classes.split()\n  \n def __iter__(self):\n  return iter(self._get_class_value().split())\n  \n def __len__(self):\n  return len(self._get_class_value().split())\n  \n  \n  \n def update(self,values):\n  ''\n\n  \n  classes=self._get_class_value().split()\n  extended=False\n  for value in values:\n   if value not in classes:\n    classes.append(value)\n    extended=True\n  if extended:\n   self._attributes['class']=' '.join(classes)\n   \n def toggle(self,value):\n  ''\n\n\n\n\n  \n  if not value or re.search(r'\\s',value):\n   raise ValueError(\"Invalid class name: %r\"%value)\n  classes=self._get_class_value().split()\n  try :\n   classes.remove(value)\n   enabled=False\n  except ValueError:\n   classes.append(value)\n   enabled=True\n  if classes:\n   self._attributes['class']=' '.join(classes)\n  else :\n   del self._attributes['class']\n  return enabled\n  \n  \nclass HtmlMixin(object):\n\n def set(self,key,value=None ):\n  ''\n\n\n\n\n  \n  super(HtmlElement,self).set(key,value)\n  \n @property\n def classes(self):\n  ''\n\n  \n  return Classes(self.attrib)\n  \n @classes.setter\n def classes(self,classes):\n  assert isinstance(classes,Classes)\n  value=classes._get_class_value()\n  if value:\n   self.set('class',value)\n  elif self.get('class')is not None :\n   del self.attrib['class']\n   \n @property\n def base_url(self):\n  ''\n\n\n\n\n  \n  return self.getroottree().docinfo.URL\n  \n @property\n def forms(self):\n  ''\n\n  \n  return _forms_xpath(self)\n  \n @property\n def body(self):\n  ''\n\n\n  \n  return self.xpath('//body|//x:body',namespaces={'x':XHTML_NAMESPACE})[0]\n  \n @property\n def head(self):\n  ''\n\n\n  \n  return self.xpath('//head|//x:head',namespaces={'x':XHTML_NAMESPACE})[0]\n  \n @property\n def label(self):\n  ''\n\n  \n  id=self.get('id')\n  if not id:\n   return None\n  result=_label_xpath(self,id=id)\n  if not result:\n   return None\n  else :\n   return result[0]\n   \n @label.setter\n def label(self,label):\n  id=self.get('id')\n  if not id:\n   raise TypeError(\n   \"You cannot set a label for an element (%r) that has no id\"\n   %self)\n  if _nons(label.tag)!='label':\n   raise TypeError(\n   \"You can only assign label to a label element (not %r)\"\n   %label)\n  label.set('for',id)\n  \n @label.deleter\n def label(self):\n  label=self.label\n  if label is not None :\n   del label.attrib['for']\n   \n def drop_tree(self):\n  ''\n\n\n\n  \n  parent=self.getparent()\n  assert parent is not None\n  if self.tail:\n   previous=self.getprevious()\n   if previous is None :\n    parent.text=(parent.text or '')+self.tail\n   else :\n    previous.tail=(previous.tail or '')+self.tail\n  parent.remove(self)\n  \n def drop_tag(self):\n  ''\n\n\n\n\n\n\n\n\n\n  \n  parent=self.getparent()\n  assert parent is not None\n  previous=self.getprevious()\n  if self.text and isinstance(self.tag,basestring):\n  \n   if previous is None :\n    parent.text=(parent.text or '')+self.text\n   else :\n    previous.tail=(previous.tail or '')+self.text\n  if self.tail:\n   if len(self):\n    last=self[-1]\n    last.tail=(last.tail or '')+self.tail\n   elif previous is None :\n    parent.text=(parent.text or '')+self.tail\n   else :\n    previous.tail=(previous.tail or '')+self.tail\n  index=parent.index(self)\n  parent[index:index+1]=self[:]\n  \n def find_rel_links(self,rel):\n  ''\n\n  \n  rel=rel.lower()\n  return [el for el in _rel_links_xpath(self)\n  if el.get('rel').lower()==rel]\n  \n def find_class(self,class_name):\n  ''\n\n  \n  return _class_xpath(self,class_name=class_name)\n  \n def get_element_by_id(self,id,*default):\n  ''\n\n\n\n\n\n\n\n\n  \n  try :\n  \n  \n   return _id_xpath(self,id=id)[0]\n  except IndexError:\n   if default:\n    return default[0]\n   else :\n    raise KeyError(id)\n    \n def text_content(self):\n  ''\n\n  \n  return _collect_string_content(self)\n  \n def cssselect(self,expr,translator='html'):\n  ''\n\n\n\n\n\n\n  \n  \n  from lxml.cssselect import CSSSelector\n  return CSSSelector(expr,translator=translator)(self)\n  \n  \n  \n  \n  \n def make_links_absolute(self,base_url=None ,resolve_base_href=True ,\n handle_failures=None ):\n  ''\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  if base_url is None :\n   base_url=self.base_url\n   if base_url is None :\n    raise TypeError(\n    \"No base_url given, and the document has no base_url\")\n  if resolve_base_href:\n   self.resolve_base_href()\n   \n  if handle_failures =='ignore':\n   def link_repl(href):\n    try :\n     return urljoin(base_url,href)\n    except ValueError:\n     return href\n  elif handle_failures =='discard':\n   def link_repl(href):\n    try :\n     return urljoin(base_url,href)\n    except ValueError:\n     return None\n  elif handle_failures is None :\n   def link_repl(href):\n    return urljoin(base_url,href)\n  else :\n   raise ValueError(\n   \"unexpected value for handle_failures: %r\"%handle_failures)\n   \n  self.rewrite_links(link_repl)\n  \n def resolve_base_href(self,handle_failures=None ):\n  ''\n\n\n\n\n\n\n\n  \n  base_href=None\n  basetags=self.xpath('//base[@href]|//x:base[@href]',\n  namespaces={'x':XHTML_NAMESPACE})\n  for b in basetags:\n   base_href=b.get('href')\n   b.drop_tree()\n  if not base_href:\n   return\n  self.make_links_absolute(base_href,resolve_base_href=False ,\n  handle_failures=handle_failures)\n  \n def iterlinks(self):\n  ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  link_attrs=defs.link_attrs\n  for el in self.iter(etree.Element):\n   attribs=el.attrib\n   tag=_nons(el.tag)\n   if tag =='object':\n    codebase=None\n    \n    \n    if 'codebase'in attribs:\n     codebase=el.get('codebase')\n     yield (el,'codebase',codebase,0)\n    for attrib in ('classid','data'):\n     if attrib in attribs:\n      value=el.get(attrib)\n      if codebase is not None :\n       value=urljoin(codebase,value)\n      yield (el,attrib,value,0)\n    if 'archive'in attribs:\n     for match in _archive_re.finditer(el.get('archive')):\n      value=match.group(0)\n      if codebase is not None :\n       value=urljoin(codebase,value)\n      yield (el,'archive',value,match.start())\n   else :\n    for attrib in link_attrs:\n     if attrib in attribs:\n      yield (el,attrib,attribs[attrib],0)\n   if tag =='meta':\n    http_equiv=attribs.get('http-equiv','').lower()\n    if http_equiv =='refresh':\n     content=attribs.get('content','')\n     match=_parse_meta_refresh_url(content)\n     url=(match.group('url')if match else content).strip()\n     \n     \n     if url:\n      url,pos=_unquote_match(\n      url,match.start('url')if match else content.find(url))\n      yield (el,'content',url,pos)\n   elif tag =='param':\n    valuetype=el.get('valuetype')or ''\n    if valuetype.lower()=='ref':\n    \n    \n    \n    \n    \n    \n     yield (el,'value',el.get('value'),0)\n   elif tag =='style'and el.text:\n    urls=[\n    \n    _unquote_match(match.group(1),match.start(1))[::-1]\n    for match in _iter_css_urls(el.text)\n    ]+[\n    (match.start(1),match.group(1))\n    for match in _iter_css_imports(el.text)\n    ]\n    if urls:\n    \n    \n    \n     urls.sort(reverse=True )\n     for start,url in urls:\n      yield (el,None ,url,start)\n   if 'style'in attribs:\n    urls=list(_iter_css_urls(attribs['style']))\n    if urls:\n    \n     for match in urls[::-1]:\n      url,start=_unquote_match(match.group(1),match.start(1))\n      yield (el,'style',url,start)\n      \n def rewrite_links(self,link_repl_func,resolve_base_href=True ,\n base_href=None ):\n  ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  if base_href is not None :\n  \n  \n   self.make_links_absolute(\n   base_href,resolve_base_href=resolve_base_href)\n  elif resolve_base_href:\n   self.resolve_base_href()\n   \n  for el,attrib,link,pos in self.iterlinks():\n   new_link=link_repl_func(link.strip())\n   if new_link ==link:\n    continue\n   if new_link is None :\n   \n    if attrib is None :\n     el.text=''\n    else :\n     del el.attrib[attrib]\n    continue\n    \n   if attrib is None :\n    new=el.text[:pos]+new_link+el.text[pos+len(link):]\n    el.text=new\n   else :\n    cur=el.get(attrib)\n    if not pos and len(cur)==len(link):\n     new=new_link\n    else :\n     new=cur[:pos]+new_link+cur[pos+len(link):]\n    el.set(attrib,new)\n    \n    \nclass _MethodFunc(object):\n ''\n\n\n\n\n\n \n def __init__(self,name,copy=False ,source_class=HtmlMixin):\n  self.name=name\n  self.copy=copy\n  self.__doc__=getattr(source_class,self.name).__doc__\n def __call__(self,doc,*args,**kw):\n  result_type=type(doc)\n  if isinstance(doc,basestring):\n   if 'copy'in kw:\n    raise TypeError(\n    \"The keyword 'copy' can only be used with element inputs to %s, not a string input\"%self.name)\n   doc=fromstring(doc,**kw)\n  else :\n   if 'copy'in kw:\n    make_a_copy=kw.pop('copy')\n   else :\n    make_a_copy=self.copy\n   if make_a_copy:\n    doc=copy.deepcopy(doc)\n  meth=getattr(doc,self.name)\n  result=meth(*args,**kw)\n  \n  if result is None :\n  \n   return _transform_result(result_type,doc)\n  else :\n   return result\n   \n   \nfind_rel_links=_MethodFunc('find_rel_links',copy=False )\nfind_class=_MethodFunc('find_class',copy=False )\nmake_links_absolute=_MethodFunc('make_links_absolute',copy=True )\nresolve_base_href=_MethodFunc('resolve_base_href',copy=True )\niterlinks=_MethodFunc('iterlinks',copy=False )\nrewrite_links=_MethodFunc('rewrite_links',copy=True )\n\n\nclass HtmlComment(etree.CommentBase,HtmlMixin):\n pass\n \n \nclass HtmlElement(etree.ElementBase,HtmlMixin):\n\n cssselect=HtmlMixin.cssselect\n set=HtmlMixin.set\n \n \nclass HtmlProcessingInstruction(etree.PIBase,HtmlMixin):\n pass\n \n \nclass HtmlEntity(etree.EntityBase,HtmlMixin):\n pass\n \n \nclass HtmlElementClassLookup(etree.CustomElementClassLookup):\n ''\n\n\n\n\n\n\n \n _default_element_classes={}\n \n def __init__(self,classes=None ,mixins=None ):\n  etree.CustomElementClassLookup.__init__(self)\n  if classes is None :\n   classes=self._default_element_classes.copy()\n  if mixins:\n   mixers={}\n   for name,value in mixins:\n    if name =='*':\n     for n in classes.keys():\n      mixers.setdefault(n,[]).append(value)\n    else :\n     mixers.setdefault(name,[]).append(value)\n   for name,mix_bases in mixers.items():\n    cur=classes.get(name,HtmlElement)\n    bases=tuple(mix_bases+[cur])\n    classes[name]=type(cur.__name__,bases,{})\n  self._element_classes=classes\n  \n def lookup(self,node_type,document,namespace,name):\n  if node_type =='element':\n   return self._element_classes.get(name.lower(),HtmlElement)\n  elif node_type =='comment':\n   return HtmlComment\n  elif node_type =='PI':\n   return HtmlProcessingInstruction\n  elif node_type =='entity':\n   return HtmlEntity\n   \n  return None\n  \n  \n  \n  \n  \n  \n_looks_like_full_html_unicode=re.compile(\nunicode(r'^\\s*<(?:html|!doctype)'),re.I).match\n_looks_like_full_html_bytes=re.compile(\nr'^\\s*<(?:html|!doctype)'.encode('ascii'),re.I).match\n\n\ndef document_fromstring(html,parser=None ,ensure_head_body=False ,**kw):\n if parser is None :\n  parser=html_parser\n value=etree.fromstring(html,parser,**kw)\n if value is None :\n  raise etree.ParserError(\n  \"Document is empty\")\n if ensure_head_body and value.find('head')is None :\n  value.insert(0,Element('head'))\n if ensure_head_body and value.find('body')is None :\n  value.append(Element('body'))\n return value\n \n \ndef fragments_fromstring(html,no_leading_text=False ,base_url=None ,\nparser=None ,**kw):\n ''\n\n\n\n\n\n\n\n \n if parser is None :\n  parser=html_parser\n  \n if isinstance(html,bytes):\n  if not _looks_like_full_html_bytes(html):\n  \n   html=('<html><body>'.encode('ascii')+html+\n   '</body></html>'.encode('ascii'))\n else :\n  if not _looks_like_full_html_unicode(html):\n   html='<html><body>%s</body></html>'%html\n doc=document_fromstring(html,parser=parser,base_url=base_url,**kw)\n assert _nons(doc.tag)=='html'\n bodies=[e for e in doc if _nons(e.tag)=='body']\n assert len(bodies)==1,(\"too many bodies: %r in %r\"%(bodies,html))\n body=bodies[0]\n elements=[]\n if no_leading_text and body.text and body.text.strip():\n  raise etree.ParserError(\n  \"There is leading text: %r\"%body.text)\n if body.text and body.text.strip():\n  elements.append(body.text)\n elements.extend(body)\n \n \n return elements\n \n \ndef fragment_fromstring(html,create_parent=False ,base_url=None ,\nparser=None ,**kw):\n ''\n\n\n\n\n\n\n\n\n\n\n\n \n if parser is None :\n  parser=html_parser\n  \n accept_leading_text=bool(create_parent)\n \n elements=fragments_fromstring(\n html,parser=parser,no_leading_text=not accept_leading_text,\n base_url=base_url,**kw)\n \n if create_parent:\n  if not isinstance(create_parent,basestring):\n   create_parent='div'\n  new_root=Element(create_parent)\n  if elements:\n   if isinstance(elements[0],basestring):\n    new_root.text=elements[0]\n    del elements[0]\n   new_root.extend(elements)\n  return new_root\n  \n if not elements:\n  raise etree.ParserError('No elements found')\n if len(elements)>1:\n  raise etree.ParserError(\n  \"Multiple elements found (%s)\"\n  %', '.join([_element_name(e)for e in elements]))\n el=elements[0]\n if el.tail and el.tail.strip():\n  raise etree.ParserError(\n  \"Element followed by text: %r\"%el.tail)\n el.tail=None\n return el\n \n \ndef fromstring(html,base_url=None ,parser=None ,**kw):\n ''\n\n\n\n\n\n\n \n if parser is None :\n  parser=html_parser\n if isinstance(html,bytes):\n  is_full_html=_looks_like_full_html_bytes(html)\n else :\n  is_full_html=_looks_like_full_html_unicode(html)\n doc=document_fromstring(html,parser=parser,base_url=base_url,**kw)\n if is_full_html:\n  return doc\n  \n bodies=doc.findall('body')\n if not bodies:\n  bodies=doc.findall('{%s}body'%XHTML_NAMESPACE)\n if bodies:\n  body=bodies[0]\n  if len(bodies)>1:\n  \n  \n   for other_body in bodies[1:]:\n    if other_body.text:\n     if len(body):\n      body[-1].tail=(body[-1].tail or '')+other_body.text\n     else :\n      body.text=(body.text or '')+other_body.text\n    body.extend(other_body)\n    \n    \n    other_body.drop_tree()\n else :\n  body=None\n heads=doc.findall('head')\n if not heads:\n  heads=doc.findall('{%s}head'%XHTML_NAMESPACE)\n if heads:\n \n  head=heads[0]\n  if len(heads)>1:\n   for other_head in heads[1:]:\n    head.extend(other_head)\n    \n    other_head.drop_tree()\n  return doc\n if body is None :\n  return doc\n if (len(body)==1 and (not body.text or not body.text.strip())\n and (not body[-1].tail or not body[-1].tail.strip())):\n \n \n  return body[0]\n  \n  \n  \n if _contains_block_level_tag(body):\n  body.tag='div'\n else :\n  body.tag='span'\n return body\n \n \ndef parse(filename_or_url,parser=None ,base_url=None ,**kw):\n ''\n\n\n\n\n\n\n \n if parser is None :\n  parser=html_parser\n return etree.parse(filename_or_url,parser,base_url=base_url,**kw)\n \n \ndef _contains_block_level_tag(el):\n\n\n for el in el.iter(etree.Element):\n  if _nons(el.tag)in defs.block_tags:\n   return True\n return False\n \n \ndef _element_name(el):\n if isinstance(el,etree.CommentBase):\n  return 'comment'\n elif isinstance(el,basestring):\n  return 'string'\n else :\n  return _nons(el.tag)\n  \n  \n  \n  \n  \n  \nclass FormElement(HtmlElement):\n ''\n\n \n \n @property\n def inputs(self):\n  ''\n\n\n\n  \n  return InputGetter(self)\n  \n @property\n def fields(self):\n  ''\n\n\n\n  \n  return FieldsDict(self.inputs)\n  \n @fields.setter\n def fields(self,value):\n  fields=self.fields\n  prev_keys=fields.keys()\n  for key,value in value.items():\n   if key in prev_keys:\n    prev_keys.remove(key)\n   fields[key]=value\n  for key in prev_keys:\n   if key is None :\n   \n   \n    continue\n   fields[key]=None\n   \n def _name(self):\n  if self.get('name'):\n   return self.get('name')\n  elif self.get('id'):\n   return '#'+self.get('id')\n  iter_tags=self.body.iter\n  forms=list(iter_tags('form'))\n  if not forms:\n   forms=list(iter_tags('{%s}form'%XHTML_NAMESPACE))\n  return str(forms.index(self))\n  \n def form_values(self):\n  ''\n\n\n  \n  results=[]\n  for el in self.inputs:\n   name=el.name\n   if not name or 'disabled'in el.attrib:\n    continue\n   tag=_nons(el.tag)\n   if tag =='textarea':\n    results.append((name,el.value))\n   elif tag =='select':\n    value=el.value\n    if el.multiple:\n     for v in value:\n      results.append((name,v))\n    elif value is not None :\n     results.append((name,el.value))\n   else :\n    assert tag =='input',(\n    \"Unexpected tag: %r\"%el)\n    if el.checkable and not el.checked:\n     continue\n    if el.type in ('submit','image','reset','file'):\n     continue\n    value=el.value\n    if value is not None :\n     results.append((name,el.value))\n  return results\n  \n @property\n def action(self):\n  ''\n\n  \n  base_url=self.base_url\n  action=self.get('action')\n  if base_url and action is not None :\n   return urljoin(base_url,action)\n  else :\n   return action\n   \n @action.setter\n def action(self,value):\n  self.set('action',value)\n  \n @action.deleter\n def action(self):\n  attrib=self.attrib\n  if 'action'in attrib:\n   del attrib['action']\n   \n @property\n def method(self):\n  ''\n\n\n  \n  return self.get('method','GET').upper()\n  \n @method.setter\n def method(self,value):\n  self.set('method',value.upper())\n  \n  \nHtmlElementClassLookup._default_element_classes['form']=FormElement\n\n\ndef submit_form(form,extra_values=None ,open_http=None ):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n values=form.form_values()\n if extra_values:\n  if hasattr(extra_values,'items'):\n   extra_values=extra_values.items()\n  values.extend(extra_values)\n if open_http is None :\n  open_http=open_http_urllib\n if form.action:\n  url=form.action\n else :\n  url=form.base_url\n return open_http(form.method,url,values)\n \n \ndef open_http_urllib(method,url,values):\n if not url:\n  raise ValueError(\"cannot submit, no URL provided\")\n  \n try :\n  from urllib import urlencode,urlopen\n except ImportError:\n  from urllib.request import urlopen\n  from urllib.parse import urlencode\n if method =='GET':\n  if '?'in url:\n   url +='&'\n  else :\n   url +='?'\n  url +=urlencode(values)\n  data=None\n else :\n  data=urlencode(values)\n  if not isinstance(data,bytes):\n   data=data.encode('ASCII')\n return urlopen(url,data)\n \n \nclass FieldsDict(MutableMapping):\n\n def __init__(self,inputs):\n  self.inputs=inputs\n def __getitem__(self,item):\n  return self.inputs[item].value\n def __setitem__(self,item,value):\n  self.inputs[item].value=value\n def __delitem__(self,item):\n  raise KeyError(\n  \"You cannot remove keys from ElementDict\")\n def keys(self):\n  return self.inputs.keys()\n def __contains__(self,item):\n  return item in self.inputs\n def __iter__(self):\n  return iter(self.inputs.keys())\n def __len__(self):\n  return len(self.inputs)\n  \n def __repr__(self):\n  return '<%s for form %s>'%(\n  self.__class__.__name__,\n  self.inputs.form._name())\n  \n  \nclass InputGetter(object):\n\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n def __init__(self,form):\n  self.form=form\n  \n def __repr__(self):\n  return '<%s for form %s>'%(\n  self.__class__.__name__,\n  self.form._name())\n  \n  \n  \n  \n def __getitem__(self,name):\n  fields=[field for field in self if field.name ==name]\n  if not fields:\n   raise KeyError(\"No input element with the name %r\"%name)\n   \n  input_type=fields[0].get('type')\n  if input_type =='radio'and len(fields)>1:\n   group=RadioGroup(fields)\n   group.name=name\n   return group\n  elif input_type =='checkbox'and len(fields)>1:\n   group=CheckboxGroup(fields)\n   group.name=name\n   return group\n  else :\n  \n   return fields[0]\n   \n def __contains__(self,name):\n  for field in self:\n   if field.name ==name:\n    return True\n  return False\n  \n def keys(self):\n  ''\n\n\n\n  \n  names=[]\n  seen={None }\n  for el in self:\n   name=el.name\n   if name not in seen:\n    names.append(name)\n    seen.add(name)\n  return names\n  \n def items(self):\n  ''\n\n\n\n  \n  items=[]\n  seen=set()\n  for el in self:\n   name=el.name\n   if name not in seen:\n    seen.add(name)\n    items.append((name,self[name]))\n  return items\n  \n def __iter__(self):\n  return self.form.iter('select','input','textarea')\n  \n def __len__(self):\n  return sum(1 for _ in self)\n  \n  \nclass InputMixin(object):\n ''\n\n \n @property\n def name(self):\n  ''\n\n  \n  return self.get('name')\n  \n @name.setter\n def name(self,value):\n  self.set('name',value)\n  \n @name.deleter\n def name(self):\n  attrib=self.attrib\n  if 'name'in attrib:\n   del attrib['name']\n   \n def __repr__(self):\n  type_name=getattr(self,'type',None )\n  if type_name:\n   type_name=' type=%r'%type_name\n  else :\n   type_name=''\n  return '<%s %x name=%r%s>'%(\n  self.__class__.__name__,id(self),self.name,type_name)\n  \n  \nclass TextareaElement(InputMixin,HtmlElement):\n ''\n\n\n \n @property\n def value(self):\n  ''\n\n  \n  content=self.text or ''\n  if self.tag.startswith(\"{%s}\"%XHTML_NAMESPACE):\n   serialisation_method='xml'\n  else :\n   serialisation_method='html'\n  for el in self:\n  \n   content +=etree.tostring(\n   el,method=serialisation_method,encoding='unicode')\n  return content\n  \n @value.setter\n def value(self,value):\n  del self[:]\n  self.text=value\n  \n @value.deleter\n def value(self):\n  self.text=''\n  del self[:]\n  \n  \nHtmlElementClassLookup._default_element_classes['textarea']=TextareaElement\n\n\nclass SelectElement(InputMixin,HtmlElement):\n ''\n\n\n\n\n\n\n\n\n\n \n @property\n def value(self):\n  ''\n\n\n\n\n  \n  if self.multiple:\n   return MultipleSelectOptions(self)\n  options=_options_xpath(self)\n  \n  try :\n   selected_option=next(el for el in reversed(options)if el.get('selected')is not None )\n  except StopIteration:\n   try :\n    selected_option=next(el for el in options if el.get('disabled')is None )\n   except StopIteration:\n    return None\n  value=selected_option.get('value')\n  if value is None :\n   value=(selected_option.text or '').strip()\n  return value\n  \n @value.setter\n def value(self,value):\n  if self.multiple:\n   if isinstance(value,basestring):\n    raise TypeError(\"You must pass in a sequence\")\n   values=self.value\n   values.clear()\n   values.update(value)\n   return\n  checked_option=None\n  if value is not None :\n   for el in _options_xpath(self):\n    opt_value=el.get('value')\n    if opt_value is None :\n     opt_value=(el.text or '').strip()\n    if opt_value ==value:\n     checked_option=el\n     break\n   else :\n    raise ValueError(\n    \"There is no option with the value of %r\"%value)\n  for el in _options_xpath(self):\n   if 'selected'in el.attrib:\n    del el.attrib['selected']\n  if checked_option is not None :\n   checked_option.set('selected','')\n   \n @value.deleter\n def value(self):\n \n  if self.multiple:\n   self.value.clear()\n  else :\n   self.value=None\n   \n @property\n def value_options(self):\n  ''\n\n\n  \n  options=[]\n  for el in _options_xpath(self):\n   value=el.get('value')\n   if value is None :\n    value=(el.text or '').strip()\n   options.append(value)\n  return options\n  \n @property\n def multiple(self):\n  ''\n\n  \n  return 'multiple'in self.attrib\n  \n @multiple.setter\n def multiple(self,value):\n  if value:\n   self.set('multiple','')\n  elif 'multiple'in self.attrib:\n   del self.attrib['multiple']\n   \n   \nHtmlElementClassLookup._default_element_classes['select']=SelectElement\n\n\nclass MultipleSelectOptions(SetMixin):\n ''\n\n\n\n\n \n \n def __init__(self,select):\n  self.select=select\n  \n @property\n def options(self):\n  ''\n\n  \n  return iter(_options_xpath(self.select))\n  \n def __iter__(self):\n  for option in self.options:\n   if 'selected'in option.attrib:\n    opt_value=option.get('value')\n    if opt_value is None :\n     opt_value=(option.text or '').strip()\n    yield opt_value\n    \n def add(self,item):\n  for option in self.options:\n   opt_value=option.get('value')\n   if opt_value is None :\n    opt_value=(option.text or '').strip()\n   if opt_value ==item:\n    option.set('selected','')\n    break\n  else :\n   raise ValueError(\n   \"There is no option with the value %r\"%item)\n   \n def remove(self,item):\n  for option in self.options:\n   opt_value=option.get('value')\n   if opt_value is None :\n    opt_value=(option.text or '').strip()\n   if opt_value ==item:\n    if 'selected'in option.attrib:\n     del option.attrib['selected']\n    else :\n     raise ValueError(\n     \"The option %r is not currently selected\"%item)\n    break\n  else :\n   raise ValueError(\n   \"There is not option with the value %r\"%item)\n   \n def __repr__(self):\n  return '<%s {%s} for select name=%r>'%(\n  self.__class__.__name__,\n  ', '.join([repr(v)for v in self]),\n  self.select.name)\n  \n  \nclass RadioGroup(list):\n ''\n\n\n\n\n\n\n \n @property\n def value(self):\n  ''\n\n\n  \n  for el in self:\n   if 'checked'in el.attrib:\n    return el.get('value')\n  return None\n  \n @value.setter\n def value(self,value):\n  checked_option=None\n  if value is not None :\n   for el in self:\n    if el.get('value')==value:\n     checked_option=el\n     break\n   else :\n    raise ValueError(\"There is no radio input with the value %r\"%value)\n  for el in self:\n   if 'checked'in el.attrib:\n    del el.attrib['checked']\n  if checked_option is not None :\n   checked_option.set('checked','')\n   \n @value.deleter\n def value(self):\n  self.value=None\n  \n @property\n def value_options(self):\n  ''\n\n  \n  return [el.get('value')for el in self]\n  \n def __repr__(self):\n  return '%s(%s)'%(\n  self.__class__.__name__,\n  list.__repr__(self))\n  \n  \nclass CheckboxGroup(list):\n ''\n\n\n\n\n\n\n\n \n @property\n def value(self):\n  ''\n\n\n  \n  return CheckboxValues(self)\n  \n @value.setter\n def value(self,value):\n  values=self.value\n  values.clear()\n  if not hasattr(value,'__iter__'):\n   raise ValueError(\n   \"A CheckboxGroup (name=%r) must be set to a sequence (not %r)\"\n   %(self[0].name,value))\n  values.update(value)\n  \n @value.deleter\n def value(self):\n  self.value.clear()\n  \n @property\n def value_options(self):\n  ''\n\n  \n  return [el.get('value')for el in self]\n  \n def __repr__(self):\n  return '%s(%s)'%(\n  self.__class__.__name__,list.__repr__(self))\n  \n  \nclass CheckboxValues(SetMixin):\n ''\n\n\n \n \n def __init__(self,group):\n  self.group=group\n  \n def __iter__(self):\n  return iter([\n  el.get('value')\n  for el in self.group\n  if 'checked'in el.attrib])\n  \n def add(self,value):\n  for el in self.group:\n   if el.get('value')==value:\n    el.set('checked','')\n    break\n  else :\n   raise KeyError(\"No checkbox with value %r\"%value)\n   \n def remove(self,value):\n  for el in self.group:\n   if el.get('value')==value:\n    if 'checked'in el.attrib:\n     del el.attrib['checked']\n    else :\n     raise KeyError(\n     \"The checkbox with value %r was already unchecked\"%value)\n    break\n  else :\n   raise KeyError(\n   \"No checkbox with value %r\"%value)\n   \n def __repr__(self):\n  return '<%s {%s} for checkboxes name=%r>'%(\n  self.__class__.__name__,\n  ', '.join([repr(v)for v in self]),\n  self.group.name)\n  \n  \nclass InputElement(InputMixin,HtmlElement):\n ''\n\n\n\n\n\n\n\n\n\n\n\n \n \n \n @property\n def value(self):\n  ''\n\n\n\n\n\n  \n  if self.checkable:\n   if self.checked:\n    return self.get('value')or 'on'\n   else :\n    return None\n  return self.get('value')\n  \n @value.setter\n def value(self,value):\n  if self.checkable:\n   if not value:\n    self.checked=False\n   else :\n    self.checked=True\n    if isinstance(value,basestring):\n     self.set('value',value)\n  else :\n   self.set('value',value)\n   \n @value.deleter\n def value(self):\n  if self.checkable:\n   self.checked=False\n  else :\n   if 'value'in self.attrib:\n    del self.attrib['value']\n    \n @property\n def type(self):\n  ''\n\n  \n  return self.get('type','text').lower()\n  \n @type.setter\n def type(self,value):\n  self.set('type',value)\n  \n @property\n def checkable(self):\n  ''\n\n  \n  return self.type in ('checkbox','radio')\n  \n @property\n def checked(self):\n  ''\n\n\n\n\n  \n  if not self.checkable:\n   raise AttributeError('Not a checkable input type')\n  return 'checked'in self.attrib\n  \n @checked.setter\n def checked(self,value):\n  if not self.checkable:\n   raise AttributeError('Not a checkable input type')\n  if value:\n   self.set('checked','')\n  else :\n   attrib=self.attrib\n   if 'checked'in attrib:\n    del attrib['checked']\n    \n    \nHtmlElementClassLookup._default_element_classes['input']=InputElement\n\n\nclass LabelElement(HtmlElement):\n ''\n\n\n\n\n \n @property\n def for_element(self):\n  ''\n\n\n  \n  id=self.get('for')\n  if not id:\n   return None\n  return self.body.get_element_by_id(id)\n  \n @for_element.setter\n def for_element(self,other):\n  id=other.get('id')\n  if not id:\n   raise TypeError(\n   \"Element %r has no id attribute\"%other)\n  self.set('for',id)\n  \n @for_element.deleter\n def for_element(self):\n  attrib=self.attrib\n  if 'id'in attrib:\n   del attrib['id']\n   \n   \nHtmlElementClassLookup._default_element_classes['label']=LabelElement\n\n\n\n\n\n\ndef html_to_xhtml(html):\n ''\n\n \n try :\n  html=html.getroot()\n except AttributeError:\n  pass\n prefix=\"{%s}\"%XHTML_NAMESPACE\n for el in html.iter(etree.Element):\n  tag=el.tag\n  if tag[0]!='{':\n   el.tag=prefix+tag\n   \n   \ndef xhtml_to_html(xhtml):\n ''\n\n \n try :\n  xhtml=xhtml.getroot()\n except AttributeError:\n  pass\n prefix=\"{%s}\"%XHTML_NAMESPACE\n prefix_len=len(prefix)\n for el in xhtml.iter(prefix+\"*\"):\n  el.tag=el.tag[prefix_len:]\n  \n  \n  \n  \n__str_replace_meta_content_type=re.compile(\nr'<meta http-equiv=\"Content-Type\"[^>]*>').sub\n__bytes_replace_meta_content_type=re.compile(\nr'<meta http-equiv=\"Content-Type\"[^>]*>'.encode('ASCII')).sub\n\n\ndef tostring(doc,pretty_print=False ,include_meta_content_type=False ,\nencoding=None ,method=\"html\",with_tail=True ,doctype=None ):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n html=etree.tostring(doc,method=method,pretty_print=pretty_print,\n encoding=encoding,with_tail=with_tail,\n doctype=doctype)\n if method =='html'and not include_meta_content_type:\n  if isinstance(html,str):\n   html=__str_replace_meta_content_type('',html)\n  else :\n   html=__bytes_replace_meta_content_type(bytes(),html)\n return html\n \n \ntostring.__doc__=__fix_docstring(tostring.__doc__)\n\n\ndef open_in_browser(doc,encoding=None ):\n ''\n\n\n\n \n import os\n import webbrowser\n import tempfile\n if not isinstance(doc,etree._ElementTree):\n  doc=etree.ElementTree(doc)\n handle,fn=tempfile.mkstemp(suffix='.html')\n f=os.fdopen(handle,'wb')\n try :\n  doc.write(f,method=\"html\",encoding=encoding or doc.docinfo.encoding or \"UTF-8\")\n finally :\n \n  f.close()\n url='file://'+fn.replace(os.path.sep,'/')\n print(url)\n webbrowser.open(url)\n \n \n \n \n \n \nclass HTMLParser(etree.HTMLParser):\n ''\n\n \n def __init__(self,**kwargs):\n  super(HTMLParser,self).__init__(**kwargs)\n  self.set_element_class_lookup(HtmlElementClassLookup())\n  \n  \nclass XHTMLParser(etree.XMLParser):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n def __init__(self,**kwargs):\n  super(XHTMLParser,self).__init__(**kwargs)\n  self.set_element_class_lookup(HtmlElementClassLookup())\n  \n  \ndef Element(*args,**kw):\n ''\n\n\n \n v=html_parser.makeelement(*args,**kw)\n return v\n \n \nhtml_parser=HTMLParser()\nxhtml_parser=XHTMLParser()\n", ["__future__", "bpmn2camel.camel_dsl.Json2Camel.lxml", "bpmn2camel.camel_dsl.Json2Camel.lxml.html", "bpmn2camel.camel_dsl.Json2Camel.lxml.html._setmixin", "collections", "collections.abc", "copy", "functools", "lxml.cssselect", "os", "re", "sys", "tempfile", "urllib", "urllib.parse", "urllib.request", "urlparse", "webbrowser"], 1], "bpmn2camel.camel_dsl.Json2Camel.lxml.includes": [".py", "", [], 1], "bpmn2camel.camel_dsl.Json2Camel.lxml.isoschematron": [".py", "''\n\n\n\nimport sys\nimport os.path\nfrom lxml import etree as _etree\n\n\n\ntry :\n unicode\nexcept NameError:\n\n unicode=str\ntry :\n basestring\nexcept NameError:\n\n basestring=str\n \n \n__all__=['extract_xsd','extract_rng','iso_dsdl_include',\n'iso_abstract_expand','iso_svrl_for_xslt1',\n'svrl_validation_errors','schematron_schema_valid',\n'stylesheet_params','Schematron']\n\n\n\n\n\nXML_SCHEMA_NS=\"http://www.w3.org/2001/XMLSchema\"\nRELAXNG_NS=\"http://relaxng.org/ns/structure/1.0\"\nSCHEMATRON_NS=\"http://purl.oclc.org/dsdl/schematron\"\nSVRL_NS=\"http://purl.oclc.org/dsdl/svrl\"\n\n\n\n_schematron_root='{%s}schema'%SCHEMATRON_NS\n_xml_schema_root='{%s}schema'%XML_SCHEMA_NS\n_resources_dir=os.path.join(os.path.dirname(__file__),'resources')\n\n\n\nextract_xsd=_etree.XSLT(_etree.parse(\nos.path.join(_resources_dir,'xsl','XSD2Schtrn.xsl')))\nextract_rng=_etree.XSLT(_etree.parse(\nos.path.join(_resources_dir,'xsl','RNG2Schtrn.xsl')))\niso_dsdl_include=_etree.XSLT(_etree.parse(\nos.path.join(_resources_dir,'xsl','iso-schematron-xslt1',\n'iso_dsdl_include.xsl')))\niso_abstract_expand=_etree.XSLT(_etree.parse(\nos.path.join(_resources_dir,'xsl','iso-schematron-xslt1',\n'iso_abstract_expand.xsl')))\niso_svrl_for_xslt1=_etree.XSLT(_etree.parse(\nos.path.join(_resources_dir,\n'xsl','iso-schematron-xslt1','iso_svrl_for_xslt1.xsl')))\n\n\n\nsvrl_validation_errors=_etree.XPath(\n'//svrl:failed-assert',namespaces={'svrl':SVRL_NS})\n\n\n\nschematron_schema_valid=_etree.RelaxNG(\nfile=os.path.join(_resources_dir,'rng','iso-schematron.rng'))\n\n\ndef stylesheet_params(**kwargs):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n \n result={}\n for key,val in kwargs.items():\n  if isinstance(val,basestring):\n   val=_etree.XSLT.strparam(val)\n  elif val is None :\n   raise TypeError('None not allowed as a stylesheet parameter')\n  elif not isinstance(val,_etree.XPath):\n   val=unicode(val)\n  result[key]=val\n return result\n \n \n \ndef _stylesheet_param_dict(paramsDict,kwargsDict):\n ''\n\n\n \n \n paramsDict=dict(paramsDict)\n for k,v in kwargsDict.items():\n  if v is not None :\n   paramsDict[k]=v\n paramsDict=stylesheet_params(**paramsDict)\n return paramsDict\n \n \nclass Schematron(_etree._Validator):\n ''\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n \n _domain=_etree.ErrorDomains.SCHEMATRONV\n _level=_etree.ErrorLevels.ERROR\n _error_type=_etree.ErrorTypes.SCHEMATRONV_ASSERT\n \n \n ASSERTS_ONLY=svrl_validation_errors\n ASSERTS_AND_REPORTS=_etree.XPath(\n '//svrl:failed-assert | //svrl:successful-report',\n namespaces={'svrl':SVRL_NS})\n \n def _extract(self,element):\n  ''\n\n\n\n  \n  schematron=None\n  if element.tag ==_xml_schema_root:\n   schematron=self._extract_xsd(element)\n  elif element.nsmap[element.prefix]==RELAXNG_NS:\n  \n   schematron=self._extract_rng(element)\n  return schematron\n  \n  \n  \n  \n _extract_xsd=extract_xsd\n _extract_rng=extract_rng\n _include=iso_dsdl_include\n _expand=iso_abstract_expand\n _compile=iso_svrl_for_xslt1\n \n \n \n \n _validation_errors=ASSERTS_ONLY\n \n def __init__(self,etree=None ,file=None ,include=True ,expand=True ,\n include_params={},expand_params={},compile_params={},\n store_schematron=False ,store_xslt=False ,store_report=False ,\n phase=None ,error_finder=ASSERTS_ONLY):\n  super(Schematron,self).__init__()\n  \n  self._store_report=store_report\n  self._schematron=None\n  self._validator_xslt=None\n  self._validation_report=None\n  if error_finder is not self.ASSERTS_ONLY:\n   self._validation_errors=error_finder\n   \n   \n   \n  root=None\n  try :\n   if etree is not None :\n    if _etree.iselement(etree):\n     root=etree\n    else :\n     root=etree.getroot()\n   elif file is not None :\n    root=_etree.parse(file).getroot()\n  except Exception:\n   raise _etree.SchematronParseError(\n   \"No tree or file given: %s\"%sys.exc_info()[1])\n  if root is None :\n   raise ValueError(\"Empty tree\")\n  if root.tag ==_schematron_root:\n   schematron=root\n  else :\n   schematron=self._extract(root)\n  if schematron is None :\n   raise _etree.SchematronParseError(\n   \"Document is not a schematron schema or schematron-extractable\")\n   \n   \n  if include:\n   schematron=self._include(schematron,**include_params)\n  if expand:\n   schematron=self._expand(schematron,**expand_params)\n  if not schematron_schema_valid(schematron):\n   raise _etree.SchematronParseError(\n   \"invalid schematron schema: %s\"%\n   schematron_schema_valid.error_log)\n  if store_schematron:\n   self._schematron=schematron\n   \n  compile_kwargs={'phase':phase}\n  compile_params=_stylesheet_param_dict(compile_params,compile_kwargs)\n  validator_xslt=self._compile(schematron,**compile_params)\n  if store_xslt:\n   self._validator_xslt=validator_xslt\n  self._validator=_etree.XSLT(validator_xslt)\n  \n def __call__(self,etree):\n  ''\n\n\n  \n  self._clear_error_log()\n  result=self._validator(etree)\n  if self._store_report:\n   self._validation_report=result\n  errors=self._validation_errors(result)\n  if errors:\n   if _etree.iselement(etree):\n    fname=etree.getroottree().docinfo.URL or '<file>'\n   else :\n    fname=etree.docinfo.URL or '<file>'\n   for error in errors:\n   \n    self._append_log_message(\n    domain=self._domain,type=self._error_type,\n    level=self._level,line=0,\n    message=_etree.tostring(error,encoding='unicode'),\n    filename=fname)\n   return False\n  return True\n  \n @property\n def schematron(self):\n  ''\n\n  \n  return self._schematron\n  \n @property\n def validator_xslt(self):\n  ''\n\n  \n  return self._validator_xslt\n  \n @property\n def validation_report(self):\n  ''\n\n  \n  return self._validation_report\n", ["lxml", "os.path", "sys"], 1]}
__BRYTHON__.update_VFS(scripts)
